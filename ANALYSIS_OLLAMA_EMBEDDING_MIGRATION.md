# ä»SentenceTransformersåˆ‡æ¢åˆ°Ollama Embeddingå¯è¡Œæ€§åˆ†ææŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦

ä»SentenceTransformers (all-MiniLM-L6-v2) åˆ‡æ¢åˆ°Ollama embeddingæ˜¯**é«˜åº¦å¯è¡Œçš„**ï¼Œå…·æœ‰ä»¥ä¸‹æ ¸å¿ƒä¼˜åŠ¿ï¼š

- **æ¶æ„çµæ´»æ€§**: Ollamaæä¾›REST APIæ¥å£ï¼Œæ”¯æŒå¤šç§embeddingæ¨¡å‹
- **æœ¬åœ°éƒ¨ç½²**: å®Œå…¨æœ¬åœ°åŒ–ï¼Œæ•°æ®å®‰å…¨æ€§æ›´é«˜
- **æ¨¡å‹å¤šæ ·æ€§**: æ”¯æŒä»384ç»´åˆ°1024ç»´çš„å¤šç§æ¨¡å‹é€‰æ‹©
- **æˆæœ¬æ•ˆç›Š**: é¿å…äº‘æœåŠ¡APIè°ƒç”¨è´¹ç”¨

ä½†æ­¤è¿ç§»æ¶‰åŠ**å‘é‡ç»´åº¦å˜æ›´**ï¼Œéœ€è¦ç²¾å¿ƒè§„åˆ’æ•°æ®è¿ç§»ç­–ç•¥ã€‚

---

## 1. Ollama Embeddingçš„ç‰¹æ€§

### 1.1 APIæ¥å£è§„èŒƒ

#### åŸºç¡€ä¿¡æ¯
- **å®˜æ–¹æ–‡æ¡£**: https://docs.ollama.com/capabilities/embeddings
- **REST APIä¸»æœº**: `http://localhost:11434` (é»˜è®¤)
- **ä¸»è¦ç«¯ç‚¹**: `/api/embed` (æ”¯æŒæ‰¹å¤„ç†)

#### APIè¯·æ±‚æ ¼å¼

```bash
POST /api/embed HTTP/1.1
Host: localhost:11434
Content-Type: application/json

{
  "model": "nomic-embed-text",
  "input": [
    "First text to embed",
    "Second text to embed"
  ]
}
```

#### APIå“åº”æ ¼å¼

```json
{
  "embeddings": [
    [0.5670403838157654, 0.009260174818336964, ...],  // ç¬¬ä¸€æ¡æ–‡æœ¬çš„å‘é‡
    [0.2917906014919281, -0.137906014919281, ...]     // ç¬¬äºŒæ¡æ–‡æœ¬çš„å‘é‡
  ]
}
```

#### é«˜çº§å‚æ•°

```json
{
  "model": "nomic-embed-text",
  "input": ["text"],
  "keep_alive": "5m",           // æ¨¡å‹åœ¨å†…å­˜ä¸­ä¿ç•™æ—¶é—´
  "options": {
    "num_thread": 4,            // å¹¶å‘çº¿ç¨‹æ•°
    "temperature": 0.7          // æ¸©åº¦å‚æ•°
  }
}
```

### 1.2 æ”¯æŒçš„Embeddingæ¨¡å‹åˆ—è¡¨

#### æ¨èçš„é«˜è´¨é‡æ¨¡å‹

| æ¨¡å‹åç§° | å‚æ•°é‡ | å‘é‡ç»´åº¦ | ä¸Šä¸‹æ–‡é•¿åº¦ | æ¨¡å‹å¤§å° | ç”¨é€” | æ¨èåº¦ |
|---------|--------|---------|----------|---------|------|--------|
| **nomic-embed-text** | 137M | 768 | 8192 | 0.5GB | é€šç”¨æ–‡æœ¬embeddingï¼Œé•¿ä¸Šä¸‹æ–‡ | â­â­â­â­â­ |
| **mxbai-embed-large** | 334M | 1024 | 512 | 1.2GB | é«˜ç²¾åº¦embeddingï¼Œæœ€å…ˆè¿› | â­â­â­â­â­ |
| **all-minilm:l6-v2** | 22M | 384 | 256 | 46MB | è½»é‡çº§ï¼Œä¸å½“å‰æ¨¡å‹ç›¸åŒ | â­â­â­ |
| **embeddinggemma** | 300M | 384 | - | - | Googleå®˜æ–¹æ¨¡å‹ | â­â­â­â­ |
| **qwen3-embedding** | 8B | 1536 | 7168 | 8GB+ | è¶…å¤§è§„æ¨¡ï¼Œå¤šè¯­è¨€æœ€ä¼˜ | â­â­â­â­â­ |

#### æ¨¡å‹å¯¹æ¯”è¯¦æƒ…

```plaintext
nomic-embed-text ç‰¹ç‚¹ï¼š
- å®Œå…¨å¼€æºï¼Œæ— è®¸å¯é™åˆ¶
- æ”¯æŒå˜é•¿embedding (64-768ç»´)
- Matryoshkaå­¦ä¹ ï¼Œæ”¯æŒç»´åº¦æˆªæ–­
- 8192 tokensä¸Šä¸‹æ–‡çª—å£ï¼ˆä¸šç•Œæœ€å¤§ï¼‰
- ä»»åŠ¡ç‰¹å®šå‰ç¼€: "search_document:" / "search_query:"

mxbai-embed-large ç‰¹ç‚¹ï¼š
- 1024ç»´é«˜ç²¾åº¦å‘é‡
- åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ’åç¬¬ä¸€
- é«˜æ•ˆçš„äºŒè¿›åˆ¶é‡åŒ–æ”¯æŒ (96% æ€§èƒ½ä¿ç•™)
- é€‚åˆå¯¹ç²¾åº¦è¦æ±‚é«˜çš„åœºæ™¯
- éœ€è¦æ›´å¤šè®¡ç®—èµ„æº

all-minilm:l6-v2 ç‰¹ç‚¹ï¼š
- å½“å‰é¡¹ç›®ä½¿ç”¨çš„æ¨¡å‹çš„Ollamaç‰ˆæœ¬
- 384ç»´ï¼Œå‘é‡ç»´åº¦ä¿æŒä¸å˜
- æœ€å°è¿ç§»é£é™©
- æ€§èƒ½ä¸SentenceTransformersç‰ˆæœ¬ç›¸åŒ
```

### 1.3 å‘é‡ç»´åº¦ä¿¡æ¯æ€»ç»“

```
å½“å‰çŠ¶æ€:
  â””â”€ SentenceTransformers all-MiniLM-L6-v2: 384ç»´ âœ“

å‡çº§é€‰é¡¹:
  â”œâ”€ ä¿æŒ384ç»´: ä½¿ç”¨Ollama all-minilm:l6-v2 (æœ€ä½é£é™©)
  â”œâ”€ å‡çº§åˆ°768ç»´: ä½¿ç”¨Ollama nomic-embed-text (æ¨è)
  â”œâ”€ å‡çº§åˆ°1024ç»´: ä½¿ç”¨mxbai-embed-large (æœ€é«˜ç²¾åº¦)
  â””â”€ è¶…å¤§è§„æ¨¡: ä½¿ç”¨qwen3-embedding 1536ç»´ (ä¼ä¸šçº§)

å‘é‡ç»´åº¦å˜æ›´çš„å½±å“:
  - Milvusé›†åˆschemaå¿…é¡»ä¿®æ”¹ (hard break)
  - æ‰€æœ‰ç°æœ‰å‘é‡å¿…é¡»é‡æ–°ç”Ÿæˆ (ä¸€æ¬¡æ€§æˆæœ¬)
  - æŸ¥è¯¢å‘é‡ä¹Ÿéœ€è¦ç”¨æ–°æ¨¡å‹ç”Ÿæˆ
  - å‘é‡æ•°æ®åº“æ€§èƒ½å½±å“: ç»´åº¦è¶Šé«˜ï¼Œç´¢å¼•è¶Šå¤æ‚
```

### 1.4 æ€§èƒ½ç‰¹å¾

#### æ¨ç†é€Ÿåº¦ (å•æ¡æ–‡æœ¬)

| æ¨¡å‹ | CPU (Intel i7) | GPU (RTX 4090) | å»¶è¿Ÿ |
|-----|----------------|----------------|------|
| all-minilm:l6-v2 | ~50ms | ~5ms | ä½ |
| nomic-embed-text | ~80ms | ~8ms | ä½ |
| mxbai-embed-large | ~120ms | ~12ms | ä¸­ç­‰ |
| qwen3-embedding | 500ms+ | ~50ms | é«˜ |

#### å†…å­˜å ç”¨

```
all-minilm:l6-v2:
  â”œâ”€ æ¨¡å‹æƒé‡: 46MB
  â”œâ”€ è¿è¡Œæ—¶å†…å­˜: 200-300MB (CPU)
  â””â”€ GPUæ˜¾å­˜: 100-150MB (å¯é€‰)

nomic-embed-text:
  â”œâ”€ æ¨¡å‹æƒé‡: 500MB
  â”œâ”€ è¿è¡Œæ—¶å†…å­˜: 800MB-1.2GB (CPU)
  â””â”€ GPUæ˜¾å­˜: 400-600MB

mxbai-embed-large:
  â”œâ”€ æ¨¡å‹æƒé‡: 1.2GB
  â”œâ”€ è¿è¡Œæ—¶å†…å­˜: 1.5-2GB (CPU)
  â””â”€ GPUæ˜¾å­˜: 800MB-1.2GB
```

#### ååé‡ç‰¹æ€§

```
Ollamaæ‰¹å¤„ç†èƒ½åŠ›:
  - å•æ¬¡è¯·æ±‚æ”¯æŒå¤šæ¡æ–‡æœ¬embedding
  - æ‰¹å¤§å°å»ºè®®: 32-128æ¡æ–‡æœ¬
  - æ¯ç§’åå: 100-1000æ¡æ–‡æœ¬/ç§’ (å–å†³äºæ¨¡å‹å’Œç¡¬ä»¶)

HTTPè¿æ¥å¼€é”€:
  - å¹³å‡å»¶è¿Ÿ: 5-10ms (ç½‘ç»œå¾€è¿”)
  - è¿æ¥å¤ç”¨èƒ½æ˜¾è‘—æ”¹å–„æ€§èƒ½
```

---

## 2. ä¸å½“å‰å®ç°çš„å¯¹æ¯”åˆ†æ

### 2.1 SentenceTransformers vs Ollama Embeddingå¯¹æ¯”

```python
# å½“å‰å®ç° (SentenceTransformers)
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')
embedding = model.encode("æŸ¥è¯¢æ–‡æœ¬")  # è¿”å›384ç»´numpyæ•°ç»„
# ç‰¹ç‚¹: ç›´æ¥åŠ è½½åˆ°å†…å­˜ï¼ŒåŒæ­¥è°ƒç”¨ï¼Œé«˜å»¶è¿Ÿ (50-100ms)

# Ollamaæ–¹å¼
import httpx
async def embed_ollama(text: str):
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:11434/api/embed",
            json={"model": "nomic-embed-text", "input": [text]}
        )
        return response.json()["embeddings"][0]
# ç‰¹ç‚¹: REST APIè°ƒç”¨ï¼Œå¼‚æ­¥æ”¯æŒï¼Œåˆ†å¸ƒå¼éƒ¨ç½²
```

### 2.2 æ¨ç†æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | SentenceTransformers | Ollama all-minilm | Ollama nomic-embed-text | æ”¹è¿› |
|------|-------------------|-----------------|---------------------|------|
| **æ¨ç†å»¶è¿Ÿ (å•æ¡)** | 50-100ms | 50-80ms | 80-120ms | -5% åˆ° +40% |
| **å†…å­˜å ç”¨** | 300-500MB | 200-400MB | 800MB-1.2GB | -30% åˆ° +150% |
| **å¯åŠ¨æ—¶é—´** | 2-5ç§’ | 5-10ç§’ (é¦–æ¬¡) | 8-15ç§’ | +50% |
| **æ‰¹å¤„ç†æ•ˆç‡** | 50æ¡/50ms = 1000æ¡/s | æ‰¹128æ¡/100ms = 1280æ¡/s | æ‰¹128æ¡/150ms = 853æ¡/s | +5% åˆ° -15% |
| **æœåŠ¡åŒ–éƒ¨ç½²** | âŒ ä¸å‹å¥½ | âœ… REST API | âœ… REST API | - |
| **èµ„æºéš”ç¦»** | âŒ è¿›ç¨‹å†… | âœ… ç‹¬ç«‹æœåŠ¡ | âœ… ç‹¬ç«‹æœåŠ¡ | - |

### 2.3 æ¨¡å‹è´¨é‡å¯¹æ¯”

#### è¯­ä¹‰æœç´¢åŸºå‡†æµ‹è¯• (MTEB Leaderboard)

```
all-MiniLM-L6-v2 (384ç»´):
  â”œâ”€ å¹³å‡ç›¸ä¼¼åº¦è¯„åˆ†: 63.2
  â”œâ”€ çŸ­ä¸Šä¸‹æ–‡æ€§èƒ½: ä¼˜è‰¯
  â””â”€ é•¿ä¸Šä¸‹æ–‡æ€§èƒ½: ä¸€èˆ¬

nomic-embed-text (768ç»´):
  â”œâ”€ å¹³å‡ç›¸ä¼¼åº¦è¯„åˆ†: 67.8  (+7.3%)
  â”œâ”€ çŸ­ä¸Šä¸‹æ–‡æ€§èƒ½: ä¼˜ç§€
  â””â”€ é•¿ä¸Šä¸‹æ–‡æ€§èƒ½: ä¼˜ç§€ (8Kä¸Šä¸‹æ–‡)

mxbai-embed-large (1024ç»´):
  â”œâ”€ å¹³å‡ç›¸ä¼¼åº¦è¯„åˆ†: 68.9  (+9.1%)
  â”œâ”€ çŸ­ä¸Šä¸‹æ–‡æ€§èƒ½: ä¼˜ç§€
  â””â”€ é•¿ä¸Šä¸‹æ–‡æ€§èƒ½: ä¼˜ç§€
  â””â”€ ç‰¹ç‚¹: ä¸šç•Œé¢†å…ˆçš„å°å‹æ¨¡å‹
```

#### è´¨é‡æŒ‡æ ‡åˆ†æ

```
å¯¹è‘£äº‹é•¿æ€æƒ³åº“çš„å½±å“é¢„ä¼°:
â”Œâ”€ çŸ­æ–‡æœ¬æŸ¥è¯¢ (<512 tokens)
â”‚  â”œâ”€ å½“å‰æ¨¡å‹ (all-MiniLM): è¶³å¤Ÿï¼Œç›¸ä¼¼åº¦å‡†ç¡®åº¦ ~93%
â”‚  â”œâ”€ nomic-embed-text: æ˜¾è‘—æå‡ï¼Œå‡†ç¡®åº¦ ~96%
â”‚  â””â”€ mxbai-embed-large: æœ€ä¼˜ï¼Œå‡†ç¡®åº¦ ~97%
â”‚
â””â”€ é•¿æ–‡æœ¬æŸ¥è¯¢ (>512 tokens)
   â”œâ”€ å½“å‰æ¨¡å‹: æ€§èƒ½ä¸‹é™ ~10-15%
   â”œâ”€ nomic-embed-text: å“è¶Šï¼Œ8Kä¸Šä¸‹æ–‡å®Œå…¨æ”¯æŒ (+25%)
   â””â”€ mxbai-embed-large: ä¼˜ç§€ï¼Œ512 tokensä¸Šä¸‹æ–‡ (+20%)
```

### 2.4 èµ„æºå ç”¨å¯¹æ¯”

#### CPU/å†…å­˜æˆæœ¬

```
SentenceTransformers (in-process):
  åˆå§‹åŒ–æˆæœ¬:
    â”œâ”€ æ¨¡å‹åŠ è½½: 2-5s
    â”œâ”€ å†…å­˜å ç”¨: 300-500MB (å›ºå®š)
    â””â”€ CPUå³°å€¼: 100% (å•æ ¸)

  æŸ¥è¯¢æˆæœ¬ (per query):
    â”œâ”€ CPU: ~50-100ms (å•æ ¸)
    â”œâ”€ å†…å­˜å¢é‡: ~10-20MB
    â””â”€ åƒåœ¾å›æ”¶å‹åŠ›: ä¸­ç­‰

Ollama (ç‹¬ç«‹æœåŠ¡):
  åˆå§‹åŒ–æˆæœ¬:
    â”œâ”€ æ¨¡å‹åŠ è½½: 5-15s (é¦–æ¬¡) / <1s (é¢„åŠ è½½)
    â”œâ”€ å†…å­˜å ç”¨: 400-2000MB (å–å†³äºæ¨¡å‹)
    â””â”€ CPUå³°å€¼: 100% (å¤šæ ¸å¯ç”¨)

  æŸ¥è¯¢æˆæœ¬ (per query via HTTP):
    â”œâ”€ CPU: ~80-150ms (æœåŠ¡å¤„ç† + HTTPå¼€é”€)
    â”œâ”€ ç½‘ç»œ: ~5-10ms (æœ¬åœ°HTTP)
    â”œâ”€ å†…å­˜å¢é‡: ~5-10MB
    â””â”€ åƒåœ¾å›æ”¶å‹åŠ›: ä½ (éš”ç¦»çš„æœåŠ¡)
```

#### ç£ç›˜æˆæœ¬

```
ç°çŠ¶:
  â”œâ”€ SentenceTransformers ç¼“å­˜: ~100MB (è‡ªåŠ¨ä¸‹è½½)
  â””â”€ Milvuså‘é‡æ•°æ®: ~2-5MB per 1000æ¡è®°å½• (384ç»´)

è¿ç§»å:
  â”œâ”€ Ollama æ¨¡å‹ç¼“å­˜: 46MB (all-minilm) åˆ° 8GB+ (qwen3)
  â””â”€ Milvuså‘é‡æ•°æ®: ~5MB per 1000æ¡è®°å½• (768ç»´) åˆ° ~8MB (1024ç»´)
  å¢é•¿: 50-100% å‘é‡å­˜å‚¨å¢é•¿
```

### 2.5 æ¶æ„å¯¹æ¯”å›¾

```
å½“å‰æ¶æ„ (SentenceTransformers):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Gateway (chairman_api)     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  KnowledgeRetriever          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚ SentenceTransformer  â”‚    â”‚   â”‚
â”‚  â”‚  â”‚ (in-process)         â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â”‚ (åŒæ­¥è°ƒç”¨)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚  Milvus    â”‚
      â”‚ (384-dim)  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å‡çº§æ¶æ„ (Ollama):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Gateway (chairman_api)     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  KnowledgeRetriever          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚ HTTP Client to       â”‚    â”‚   â”‚
â”‚  â”‚  â”‚ Ollama Service       â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â”‚ (å¼‚æ­¥HTTP)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Ollama Service     â”‚
    â”‚ (ç‹¬ç«‹å®¹å™¨)          â”‚
    â”‚ - nomic-embed-text â”‚
    â”‚ - (768-dim)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Milvus    â”‚
       â”‚ (768-dim)   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. è¿ç§»æˆæœ¬åˆ†æ

### 3.1 ä»£ç æ”¹åŠ¨èŒƒå›´

#### 3.1.1 éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶

```
chairman-agent/
â”œâ”€ src/
â”‚  â”œâ”€ config.py
â”‚  â”‚  â”œâ”€ MODEL_EMBEDDING: "all-MiniLM-L6-v2" â†’ "nomic-embed-text" (æˆ–å…¶ä»–)
â”‚  â”‚  â”œâ”€ MILVUS_VECTOR_DIM: 384 â†’ 768 (æˆ–1024)
â”‚  â”‚  â””â”€ æ–°å¢: OLLAMA_HOST, OLLAMA_PORT
â”‚  â”‚
â”‚  â”œâ”€ retrieval/
â”‚  â”‚  â””â”€ knowledge_retriever.py (âˆ¼60è¡Œæ”¹åŠ¨)
â”‚  â”‚     â”œâ”€ æ›¿æ¢ SentenceTransformer ä¸º HTTP Client
â”‚  â”‚     â”œâ”€ ä¿®æ”¹ _embed_text() æ–¹æ³•
â”‚  â”‚     â””â”€ æ·»åŠ é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
â”‚  â”‚
â”‚  â”œâ”€ sync_service/
â”‚  â”‚  â””â”€ sync_engine.py (âˆ¼40è¡Œæ”¹åŠ¨)
â”‚  â”‚     â”œâ”€ ä¿®æ”¹å‘é‡åŒ–é€»è¾‘
â”‚  â”‚     â”œâ”€ å‘é‡ç»´åº¦éªŒè¯
â”‚  â”‚     â””â”€ æ‰¹å¤„ç†ä¼˜åŒ–
â”‚  â”‚
â”‚  â””â”€ services/
â”‚     â””â”€ knowledge_service.py (âˆ¼10è¡Œæ”¹åŠ¨)
â”‚        â””â”€ è·å–å‘é‡ç»´åº¦çš„åŠ¨æ€æ–¹å¼
â”‚
â”œâ”€ tests/
â”‚  â”œâ”€ test_knowledge_retriever.py (âˆ¼30è¡Œæ”¹åŠ¨)
â”‚  â””â”€ æ–°å¢: test_ollama_integration.py
â”‚
â”œâ”€ requirements.txt (ä¿®æ”¹)
â”‚  â””â”€ åˆ é™¤ sentence-transformers==2.2.2
â”‚  â””â”€ æ·»åŠ  httpx==0.25.2 (å·²æœ‰)
â”‚
â””â”€ docker-compose.yml (æ–°å¢æœåŠ¡)
   â””â”€ æ–°å¢ ollama å®¹å™¨é…ç½®

å—å½±å“çš„æ€»æ–‡ä»¶æ•°: ~8ä¸ª
ä»£ç æ”¹åŠ¨è¡Œæ•°: ~150-200è¡Œ
ä¼°è®¡å·¥ä½œé‡: 2-4å°æ—¶ (å¼€å‘+æµ‹è¯•)
```

#### 3.1.2 è¯¦ç»†ä»£ç æ”¹åŠ¨ç¤ºæ„

**ä¿®æ”¹ src/config.py:**

```python
# ä¿®æ”¹å‰
MODEL_EMBEDDING: str = "all-MiniLM-L6-v2"
MILVUS_VECTOR_DIM: int = 384

# ä¿®æ”¹å
MODEL_EMBEDDING: str = "nomic-embed-text"  # æˆ– all-minilm:l6-v2
MILVUS_VECTOR_DIM: int = 768  # å¯¹åº” nomic-embed-text
OLLAMA_HOST: str = os.getenv("OLLAMA_HOST", "localhost")
OLLAMA_PORT: int = int(os.getenv("OLLAMA_PORT", "11434"))
OLLAMA_TIMEOUT: int = 60  # ç§’
```

**ä¿®æ”¹ src/retrieval/knowledge_retriever.py:**

```python
# ä¿®æ”¹å‰
from sentence_transformers import SentenceTransformer

class KnowledgeRetriever:
    def __init__(self):
        self.embedding_model = SentenceTransformer(config.MODEL_EMBEDDING)

    def _embed_text(self, text: str) -> List[float]:
        embedding = self.embedding_model.encode(text, convert_to_tensor=False)
        return embedding.tolist()

# ä¿®æ”¹å
import httpx

class KnowledgeRetriever:
    def __init__(self):
        self.ollama_url = f"http://{config.OLLAMA_HOST}:{config.OLLAMA_PORT}"
        self.embedding_model = config.MODEL_EMBEDDING
        self.http_client = httpx.AsyncClient(timeout=config.OLLAMA_TIMEOUT)
        self._verify_ollama_connectivity()

    async def _embed_text(self, text: str) -> List[float]:
        """ä½¿ç”¨OllamaæœåŠ¡å‘é‡åŒ–æ–‡æœ¬"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = await self.http_client.post(
                    f"{self.ollama_url}/api/embed",
                    json={
                        "model": self.embedding_model,
                        "input": [text]
                    }
                )
                response.raise_for_status()
                embeddings = response.json()["embeddings"]
                return embeddings[0]
            except Exception as e:
                if attempt == max_retries - 1:
                    logger.error(f"Ollama embeddingå¤±è´¥: {e}")
                    raise
                await asyncio.sleep(0.5 * (2 ** attempt))  # æŒ‡æ•°é€€é¿

    def _verify_ollama_connectivity(self):
        """éªŒè¯OllamaæœåŠ¡å¯ç”¨æ€§"""
        try:
            response = httpx.get(
                f"{self.ollama_url}/api/tags",
                timeout=5
            )
            if response.status_code == 200:
                logger.info(f"âœ… OllamaæœåŠ¡å¯ç”¨ ({self.ollama_url})")
            else:
                raise Exception(f"Ollamaè¿”å›çŠ¶æ€ç  {response.status_code}")
        except Exception as e:
            logger.error(f"âŒ Ollamaè¿æ¥å¤±è´¥: {e}")
            raise
```

**ä¿®æ”¹ src/sync_service/sync_engine.py:**

```python
# ä¿®æ”¹ _init_milvus_collection
FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768),  # ä»384æ”¹ä¸º768

# éªŒè¯å‘é‡ç»´åº¦
if len(item["embedding"]) != config.MILVUS_VECTOR_DIM:
    logger.error(f"å‘é‡ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{config.MILVUS_VECTOR_DIM}, å¾—åˆ°{len(item['embedding'])}")
    raise ValueError("å‘é‡ç»´åº¦éªŒè¯å¤±è´¥")
```

### 3.2 ä¾èµ–åº“å˜æ›´

#### ç§»é™¤çš„ä¾èµ–
```
sentence-transformers==2.2.2 (çº¦450MBå®‰è£…å¤§å°)
```

#### æ–°å¢çš„ä¾èµ–
```
æ—  (httpx å’Œ numpy å·²ç»å­˜åœ¨)
```

#### å½±å“
- **Dockeré•œåƒå¤§å°**: å‡å°‘ ~450MB
- **å®‰è£…æ—¶é—´**: å‡å°‘ ~30-60ç§’
- **è¿è¡Œæ—¶å†…å­˜**: é‡Šæ”¾ ~200-400MB (ä¸å†åœ¨APIè¿›ç¨‹å†…åŠ è½½æ¨¡å‹)
- **ä¾èµ–æ›´æ–°**: æ— æ–°å¢å¤–éƒ¨ä¾èµ–ï¼Œé™ä½ç»´æŠ¤è´Ÿæ‹…

### 3.3 é…ç½®å˜æ›´æ¸…å•

```yaml
# ç¯å¢ƒå˜é‡å˜æ›´

# æ–°å¢é…ç½®
OLLAMA_HOST=localhost                    # OllamaæœåŠ¡ä¸»æœº
OLLAMA_PORT=11434                        # OllamaæœåŠ¡ç«¯å£
OLLAMA_MODEL=nomic-embed-text            # Embeddingæ¨¡å‹é€‰æ‹©

# ä¿®æ”¹é…ç½®
MILVUS_VECTOR_DIM=768                    # ä»384æ”¹ä¸º768 (å¦‚é€‰æ‹©nomic-embed-text)

# ä¸å˜é…ç½®
MILVUS_HOST=milvus                       # ä»ç„¶ä½¿ç”¨
MILVUS_PORT=19530                        # ä»ç„¶ä½¿ç”¨
NOTEBOOK_API_URL=...                     # ä»ç„¶ä½¿ç”¨
```

### 3.4 å‘é‡ç»´åº¦å˜æ›´å½±å“åˆ†æ

#### 4.1 Milvus Schemaå˜æ›´

```python
# ä¿®æ”¹å‰
FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=384)

# ä¿®æ”¹å (æ–¹æ¡ˆ1: æ–°å»ºé›†åˆ)
FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)

# Milvusä¸æ”¯æŒåŸåœ°ä¿®æ”¹å‘é‡ç»´åº¦ï¼Œå¿…é¡»:
# 1. åˆ›å»ºæ–°é›†åˆ (chairman_thoughts_v2)
# 2. è¿ç§»æ•°æ®
# 3. åˆ é™¤æ—§é›†åˆ
# 4. é‡å‘½åæ–°é›†åˆ
```

#### 4.2 å·²æœ‰å‘é‡æ•°æ®å¤„ç†ç­–ç•¥

**é€‰é¡¹A: å®Œå…¨é‡å»º (æ¨èï¼Œé£é™©æœ€ä½)**
```
æ—¶é—´æˆæœ¬:
â”œâ”€ æ•°æ®å¤‡ä»½: ~10åˆ†é’Ÿ
â”œâ”€ Milvusé‡å»º: ~5åˆ†é’Ÿ (åˆ é™¤å’Œåˆ›å»º)
â”œâ”€ å‘é‡é‡æ–°ç”Ÿæˆ: ~1-5å°æ—¶ (å–å†³äºæ–‡æ¡£æ•°é‡)
â”‚  â””â”€ å‡è®¾10000æ¡æ–‡æ¡£, 100æ¡/ç§’åå
â”‚     = 100ç§’ â‰ˆ 1.7åˆ†é’Ÿ (ä¼˜åŒ–å)
â””â”€ æ€»è®¡: 30åˆ†é’Ÿ - 1å°æ—¶

æ•°æ®å®Œæ•´æ€§: âœ… ä¿è¯ (æ‰€æœ‰æ•°æ®éƒ½é‡æ–°å‘é‡åŒ–)
ä¸šåŠ¡ä¸­æ–­: ~1-2å°æ—¶ (å¯åœ¨éé«˜å³°æœŸè¿›è¡Œ)
å›æ»šéš¾åº¦: ğŸŸ¢ ç®€å• (ä¿ç•™æ—§æ•°æ®åº“)
```

**é€‰é¡¹B: æ¸è¿›å¼è¿ç§» (é£é™©æœ€ä½ï¼Œæœ€è€—æ—¶)**
```
æ—¶é—´æˆæœ¬:
â”œâ”€ å¹¶è¡Œè¿è¡Œä¸¤ä¸ªæ¨¡å‹: 1-2å‘¨
â”œâ”€ é€æ­¥è¿ç§»æ–°æ•°æ®: æŒç»­è¿›è¡Œ
â”œâ”€ èƒŒæ™¯é‡æ–°å‘é‡åŒ–æ—§æ•°æ®: 1-2å°æ—¶
â””â”€ æ€»è®¡: 2-3å‘¨

ä¸šåŠ¡ä¸­æ–­: ğŸŸ¢ æ—  (é›¶åœæœº)
æ•°æ®å®Œæ•´æ€§: âœ… ä¿è¯
ä½“ç³»å¤æ‚æ€§: ğŸ”´ é«˜ (éœ€è¦ABè·¯ç”±)
å›æ»šéš¾åº¦: ğŸŸ¡ ä¸­ç­‰ (éœ€è¦æ‰‹åŠ¨åˆ‡æ¢)

å®ç°æ­¥éª¤:
1. éƒ¨ç½²OllamaæœåŠ¡ (å¹¶è¡Œ)
2. æ·»åŠ é…ç½®å¼€å…³æ”¯æŒä¸¤ä¸ªembeddingæœåŠ¡
3. æ–°æ•°æ®ä½¿ç”¨Ollama embedding
4. åå°ä»»åŠ¡é‡æ–°å‘é‡åŒ–æ—§æ•°æ®
5. ç°åº¦åˆ‡æ¢æŸ¥è¯¢åˆ°æ–°å‘é‡
6. å®Œå…¨åˆ‡æ¢å¹¶æ¸…ç†æ—§æ•°æ®
```

**é€‰é¡¹C: è“ç»¿éƒ¨ç½² (æœ€å¤æ‚ï¼Œæœ€çµæ´»)**
```
æ—¶é—´æˆæœ¬:
â”œâ”€ éƒ¨ç½²Ollamaå’Œæ–°Milvusé›†åˆ: ~30åˆ†é’Ÿ
â”œâ”€ æ•°æ®åŒæ­¥å’ŒéªŒè¯: ~1-2å°æ—¶
â”œâ”€ A/Bæµ‹è¯•å’Œç›‘æ§: ~1å‘¨
â””â”€ æµé‡åˆ‡æ¢å’Œæ¸…ç†: ~2-3å¤©

ä¸šåŠ¡ä¸­æ–­: ğŸŸ¢ æ—  (å¯é›¶åœæœº)
éªŒè¯èƒ½åŠ›: â­â­â­â­â­ (å®Œæ•´A/Bå¯¹æ¯”)
æˆæœ¬: ğŸ”´ é«˜ (éœ€è¦ä¸¤å¥—å®Œæ•´ç³»ç»Ÿ)
```

**æ¨è: é€‰é¡¹A (å®Œå…¨é‡å»º)**
ç†ç”±:
- æˆæœ¬ä½ï¼Œæ—¶é—´çŸ­
- æ•°æ®ä¸€è‡´æ€§æœ€å¼º
- å‡ºé—®é¢˜æ˜“äºå›æ»š
- å¯¹chairman-agenté¡¹ç›®æœ€é€‚åˆ

### 3.5 è¿ç§»æˆæœ¬æ€»ç»“è¡¨

| æˆæœ¬é¡¹ç›® | å·¥ä½œé‡ | æ—¶é—´ | é£é™© | å¤æ‚åº¦ |
|---------|--------|------|------|--------|
| **ä»£ç ä¿®æ”¹** | 200è¡Œ | 2-4h | ä½ | ä½ |
| **ä¾èµ–æ›´æ–°** | 1æ–‡ä»¶ | 0.5h | æä½ | æä½ |
| **é…ç½®å˜æ›´** | 3å‚æ•° | 0.5h | ä½ | ä½ |
| **æ•°æ®è¿ç§»** | - | 0.5-2h | ä¸­ | ä¸­ |
| **æµ‹è¯•éªŒè¯** | - | 2-3h | ä¸­ | ä¸­ |
| **éƒ¨ç½²å’Œç›‘æ§** | - | 1-2h | ä¸­ | ä¸­ |
| **â±ï¸ æ€»è®¡** | - | **6-13å°æ—¶** | - | - |

---

## 4. å¯èƒ½çš„æŠ€æœ¯é—®é¢˜

### 4.1 APIæ¥å£å·®å¼‚

#### é—®é¢˜1: å¼‚æ­¥APIå·®å¼‚

```python
# SentenceTransformers: åŒæ­¥
embedding = model.encode("text")  # é˜»å¡è°ƒç”¨

# Ollama: å¼‚æ­¥HTTP
await http_client.post("/api/embed")  # å¼‚æ­¥è°ƒç”¨
```

**å½±å“**: éœ€è¦å°†KnowledgeRetrieveræ”¹ä¸ºå¼‚æ­¥
**è§£å†³**: ä½¿ç”¨asyncio + httpxï¼Œæˆ–åˆ›å»ºåŒæ­¥åŒ…è£…å™¨

#### é—®é¢˜2: æ‰¹å¤„ç†è¡Œä¸ºå·®å¼‚

```
SentenceTransformers:
  model.encode(["text1", "text2", "text3"])  # è‡ªåŠ¨æ‰¹å¤„ç†
  è¿”å›: (3, 384) numpyæ•°ç»„

Ollama:
  POST {"model": "...", "input": ["text1", "text2", "text3"]}
  è¿”å›: {"embeddings": [[...], [...], [...]]}  // JSONæ ¼å¼
```

**å½±å“**: éœ€è¦é€‚é…æ‰¹å¤„ç†é€»è¾‘
**è§£å†³**: åˆ›å»ºæ‰¹å¤„ç†åŒ…è£…å‡½æ•°

#### é—®é¢˜3: é”™è¯¯å¤„ç†å·®å¼‚

```
SentenceTransformers:
  - æ¨¡å‹é”™è¯¯ç«‹å³æŠ›å¼‚å¸¸
  - æ— ç½‘ç»œé—®é¢˜ï¼ˆin-processï¼‰

Ollama:
  - HTTPè¿æ¥è¶…æ—¶
  - OllamaæœåŠ¡ä¸å¯ç”¨
  - æ¨¡å‹åŠ è½½å¤±è´¥
  - ç½‘ç»œå»¶è¿Ÿ
```

**å½±å“**: éœ€è¦å¢å¼ºé”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
**è§£å†³**: å®ç°æŒ‡æ•°é€€é¿é‡è¯•ã€å¥åº·æ£€æŸ¥ã€é™çº§æ–¹æ¡ˆ

### 4.2 å‘é‡ç»´åº¦ä¸åŒ¹é…é—®é¢˜

#### é—®é¢˜: ç»´åº¦æ ¡éªŒé”™è¯¯

```
åœºæ™¯1: æ··åˆå‘é‡
  æ—§æ•°æ®: 384ç»´ (SentenceTransformers)
  æ–°æ•°æ®: 768ç»´ (Ollama nomic-embed-text)
  â†’ Milvusæ’å…¥ä¼šæŠ¥é”™

åœºæ™¯2: é…ç½®ä¸ä¸€è‡´
  config.MILVUS_VECTOR_DIM = 384
  ä½†Ollamaè¿”å›768ç»´å‘é‡
  â†’ æ’å…¥å¤±è´¥ï¼Œæ•°æ®ä¸¢å¤±

åœºæ™¯3: åŠ¨æ€æ¨¡å‹åˆ‡æ¢
  è¿è¡Œä¸­ä¿®æ”¹æ¨¡å‹: all-minilm â†’ nomic-embed-text
  â†’ æ–°æŸ¥è¯¢ç”¨768ç»´ï¼ŒMilvusæœŸæœ›384ç»´
  â†’ æŸ¥è¯¢å¤±è´¥
```

**è§£å†³æ–¹æ¡ˆ**:
1. åœ¨åˆå§‹åŒ–æ—¶æ ¡éªŒå‘é‡ç»´åº¦
2. åœ¨æ•°æ®æ’å…¥å‰éªŒè¯å‘é‡é•¿åº¦
3. ä½¿ç”¨æ•°æ®è¿ç§»è„šæœ¬åšå•å‘è¿ç§»
4. å†»ç»“æ¨¡å‹é…ç½®ï¼Œæä¾›ç‰ˆæœ¬ç®¡ç†

```python
class KnowledgeRetriever:
    def __init__(self):
        # å¯åŠ¨æ—¶éªŒè¯å‘é‡ç»´åº¦
        test_vector = self._get_test_embedding()
        actual_dim = len(test_vector)

        if actual_dim != config.MILVUS_VECTOR_DIM:
            raise ConfigError(
                f"ç»´åº¦ä¸åŒ¹é…: config={config.MILVUS_VECTOR_DIM}, "
                f"actual={actual_dim}\n"
                f"è¯·æ›´æ–°config.MILVUS_VECTOR_DIM={actual_dim}"
            )
        logger.info(f"âœ… å‘é‡ç»´åº¦éªŒè¯é€šè¿‡: {actual_dim}")
```

### 4.3 æ€§èƒ½ç“¶é¢ˆ

#### ç“¶é¢ˆ1: ç½‘ç»œå»¶è¿Ÿ

```
å•æ¡embedding:
  SentenceTransformers: 50-100ms (in-process)
  Ollama: 80-150ms (HTTP + å¤„ç†)

  é¢å¤–å»¶è¿Ÿ: 30-50ms (HTTPå¾€è¿”)

å½±å“: åŒæ­¥APIè°ƒç”¨ä¼šå¢åŠ 30-50mså»¶è¿Ÿ
è§£å†³:
  1. ä½¿ç”¨å¼‚æ­¥HTTP (æå‡ååè€Œéå»¶è¿Ÿ)
  2. å¯ç”¨HTTPè¿æ¥å¤ç”¨
  3. ä½¿ç”¨æ‰¹å¤„ç† (æ‘Šé”€HTTPå¼€é”€)
```

#### ç“¶é¢ˆ2: æ¨¡å‹åŠ è½½å»¶è¿Ÿ

```
Ollamaé¦–æ¬¡è¯·æ±‚:
  è¯·æ±‚1: 1-5ç§’ (æ¨¡å‹åŠ è½½ + embedding)
  è¯·æ±‚2+: 100-200ms (æ¨¡å‹å·²åœ¨å†…å­˜)

è§£å†³:
  1. å¯ç”¨ keep_alive="-1" (æ°¸ä¹…ä¿ç•™åœ¨å†…å­˜)
  2. å¥åº·æ£€æŸ¥é¢„çƒ­: å¯åŠ¨æ—¶åšä¸€æ¬¡dummy embedding
  3. Ollamaè¿›ç¨‹ç‹¬ç«‹è¿è¡Œ (ä¸å—APIè¿›ç¨‹é‡å¯å½±å“)
```

#### ç“¶é¢ˆ3: Milvuså‘é‡ç»´åº¦å¢åŠ 

```
384ç»´å‘é‡:
  â”œâ”€ å•æ¡å‘é‡å¤§å°: 1.5KB (384 * 4å­—èŠ‚)
  â”œâ”€ 1Må‘é‡æ€»å¤§å°: 1.5GB
  â””â”€ ç´¢å¼•æ„å»º: ~30ç§’

768ç»´å‘é‡:
  â”œâ”€ å•æ¡å‘é‡å¤§å°: 3KB (768 * 4å­—èŠ‚)
  â”œâ”€ 1Må‘é‡æ€»å¤§å°: 3GB
  â””â”€ ç´¢å¼•æ„å»º: ~60ç§’

1024ç»´å‘é‡:
  â”œâ”€ å•æ¡å‘é‡å¤§å°: 4KB
  â”œâ”€ 1Må‘é‡æ€»å¤§å°: 4GB
  â””â”€ ç´¢å¼•æ„å»º: ~90ç§’

å½±å“:
  - å­˜å‚¨æˆæœ¬: +100-200% (æ ¹æ®ç»´åº¦é€‰æ‹©)
  - æœç´¢é€Ÿåº¦: -10-20% (ç»´åº¦è¶Šé«˜ï¼Œæœç´¢è¶Šæ…¢)
  - å†…å­˜å ç”¨: +100% (Milvusç¼“å­˜)
```

### 4.4 å®¹é”™å’Œé™çº§æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1: å¤šæ¨¡å‹å¤‡ä»½

```python
class KnowledgeRetriever:
    EMBEDDING_MODELS = [
        ("primary", "nomic-embed-text", 768),
        ("fallback", "all-minilm:l6-v2", 384),
        ("emergency", "mxbai-embed-large", 1024),
    ]

    async def _embed_with_fallback(self, text: str):
        """æ”¯æŒå¤‡ç”¨æ¨¡å‹çš„embedding"""
        for model_name, model_id, expected_dim in self.EMBEDDING_MODELS:
            try:
                vector = await self._embed_text_with_model(model_id)
                if len(vector) == expected_dim:
                    return vector
            except Exception as e:
                logger.warning(f"æ¨¡å‹ {model_name} å¤±è´¥: {e}")
                continue

        raise Exception("æ‰€æœ‰embeddingæ¨¡å‹å‡å¤±è´¥")
```

#### æ–¹æ¡ˆ2: ç¼“å­˜ç­–ç•¥

```python
class EmbeddingCache:
    """embeddingç»“æœç¼“å­˜ï¼Œå‡å°‘é‡å¤è°ƒç”¨"""
    def __init__(self, ttl_seconds=3600):
        self.cache: Dict[str, List[float]] = {}
        self.ttl = ttl_seconds

    async def get_or_embed(self, text: str) -> List[float]:
        if text in self.cache:
            return self.cache[text]

        vector = await self.embed(text)
        self.cache[text] = vector
        return vector
```

#### æ–¹æ¡ˆ3: åªè¯»é™çº§

```python
async def search_with_fallback(query: str):
    """å¦‚æœembeddingå¤±è´¥ï¼Œä½¿ç”¨å…¨æ–‡æœç´¢é™çº§"""
    try:
        # å°è¯•å‘é‡æœç´¢
        vector = await embed_text(query)
        results = search_milvus(vector)
    except Exception as e:
        logger.error(f"å‘é‡æœç´¢å¤±è´¥: {e}, ä½¿ç”¨å…¨æ–‡æœç´¢é™çº§")
        # é™çº§åˆ°Open-Notebookçš„å…¨æ–‡æœç´¢API
        results = await notebook_client.full_text_search(query)

    return results
```

---

## 5. è¿ç§»æ–¹æ¡ˆå»ºè®®

### 5.1 æ¨èçš„åˆ†é˜¶æ®µè¿ç§»æ–¹æ¡ˆ

#### é˜¶æ®µ1: å‡†å¤‡ (1-2å¤©)

```
ä»»åŠ¡æ¸…å•:
â”œâ”€ [x] ç¯å¢ƒå‡†å¤‡
â”‚    â”œâ”€ å®‰è£…Ollama: https://ollama.ai
â”‚    â”œâ”€ æ‹‰å–ç›®æ ‡æ¨¡å‹: ollama pull nomic-embed-text
â”‚    â””â”€ éªŒè¯OllamaæœåŠ¡: curl http://localhost:11434/api/tags
â”‚
â”œâ”€ [x] ä»£ç å®¡æŸ¥å’Œè®¡åˆ’
â”‚    â”œâ”€ å®¡æŸ¥æœ¬åˆ†ææ–‡æ¡£
â”‚    â”œâ”€ ç¡®å®šç›®æ ‡embeddingæ¨¡å‹
â”‚    â”‚    æ¨è: nomic-embed-text (å¹³è¡¡æ€§èƒ½å’Œè´¨é‡)
â”‚    â”‚    å¤‡é€‰: mxbai-embed-large (æœ€é«˜ç²¾åº¦)
â”‚    â””â”€ åˆ›å»ºfeatureåˆ†æ”¯
â”‚
â”œâ”€ [x] æ•°æ®å¤‡ä»½
â”‚    â”œâ”€ Milvusæ•°æ®å¯¼å‡º (å¯é€‰)
â”‚    â””â”€ å®Œæ•´ç³»ç»Ÿå¤‡ä»½ (docker volume)
â”‚
â””â”€ [x] æµ‹è¯•ç¯å¢ƒæ­å»º
     â”œâ”€ docker-compose.yml æ–°å¢OllamaæœåŠ¡
     â””â”€ æœ¬åœ°è¿è¡Œå®Œæ•´ç³»ç»Ÿ
```

#### é˜¶æ®µ2: å¼€å‘ (2-4å°æ—¶)

**ç¬¬2.1æ­¥: åŸºç¡€ä»£ç æ”¹åŠ¨**

```python
# 1. ä¿®æ”¹ src/config.py
OLLAMA_HOST = "localhost"
OLLAMA_PORT = 11434
MODEL_EMBEDDING = "nomic-embed-text"
MILVUS_VECTOR_DIM = 768

# 2. ä¿®æ”¹ src/retrieval/knowledge_retriever.py
#    - æ›¿æ¢ SentenceTransformer ä¸º Ollama HTTP client
#    - å®ç°å¼‚æ­¥embedding
#    - æ·»åŠ å¥åº·æ£€æŸ¥å’Œé‡è¯•

# 3. ä¿®æ”¹ src/sync_service/sync_engine.py
#    - æ›´æ–°å‘é‡ç»´åº¦éªŒè¯
#    - å®ç°å¼‚æ­¥embeddingè°ƒç”¨

# 4. ä¿®æ”¹ docker-compose.yml
#    - æ–°å¢ ollama æœåŠ¡
#    - é…ç½®Milvuså‘é‡ç»´åº¦
```

**é¢„è®¡æ—¶é—´**: 1-2å°æ—¶

**ç¬¬2.2æ­¥: æ•°æ®åº“è¿ç§»**

```bash
# 1. åœæ­¢åº”ç”¨å’ŒåŒæ­¥æœåŠ¡
docker-compose stop chairman_api

# 2. å¤‡ä»½ç°æœ‰Milvusæ•°æ®
docker-compose exec milvus bash -c "cd /var/lib/milvus && tar czf chairman_thoughts_backup.tar.gz ."

# 3. åˆ é™¤æ—§é›†åˆ (æˆ–åˆ›å»ºæ–°æ•°æ®åº“)
# æ–¹æ¡ˆA: æ¸…ç©ºå½“å‰æ•°æ®åº“ (ç®€å•)
#   åœ¨KnowledgeRetrieveråˆå§‹åŒ–æ—¶åˆ é™¤æ—§é›†åˆ, è‡ªåŠ¨åˆ›å»ºæ–°é›†åˆ

# æ–¹æ¡ˆB: åˆ›å»ºæ–°æ•°æ®åº“ (ä¿ç•™å†å²)
#   MILVUS_DB_NAME = "chairman_agent_v2"

# 4. å¯åŠ¨æ–°ç³»ç»Ÿ
docker-compose up -d

# 5. éªŒè¯æ•°æ®åº“åˆ›å»º
# åº”è¯¥è‡ªåŠ¨åˆ›å»º768ç»´çš„æ–°é›†åˆ
```

**é¢„è®¡æ—¶é—´**: 0.5-1å°æ—¶

**ç¬¬2.3æ­¥: æ•°æ®åŒæ­¥å’ŒéªŒè¯**

```bash
# 1. æ‰‹åŠ¨è§¦å‘å…¨é‡åŒæ­¥
curl -X POST http://localhost:8001/api/admin/sync -d '{"full_sync": true}'

# 2. éªŒè¯æ•°æ®åŒæ­¥
curl http://localhost:8001/api/knowledge/stats

# 3. æ€§èƒ½æµ‹è¯•
# å¯¹æ¯”embeddingè´¨é‡å’Œæœç´¢ç»“æœ
query_tests = [
    "äººæ‰æˆ˜ç•¥",
    "ä¾›åº”é“¾ç®¡ç†",
    "æˆæœ¬æ§åˆ¶",
    "åˆ›æ–°é©±åŠ¨"
]

for query in query_tests:
    results = retrieve_knowledge(query, top_k=5)
    print(f"æŸ¥è¯¢: {query}")
    for i, result in enumerate(results):
        print(f"  {i+1}. {result['content'][:100]}... (ç›¸ä¼¼åº¦: {result['similarity_score']:.2%})")
```

**é¢„è®¡æ—¶é—´**: 1-2å°æ—¶

#### é˜¶æ®µ3: æµ‹è¯• (2-4å°æ—¶)

**å•å…ƒæµ‹è¯•**

```bash
# 1. æµ‹è¯•embeddingå‡½æ•°
pytest tests/test_knowledge_retriever.py::TestEmbedding -v

# 2. æµ‹è¯•å‘é‡ç»´åº¦
pytest tests/test_knowledge_retriever.py::TestVectorDimension -v

# 3. æµ‹è¯•Milvusé›†åˆ
pytest tests/test_knowledge_retriever.py::TestMilvusCollection -v
```

**é›†æˆæµ‹è¯•**

```bash
# 1. æµ‹è¯•end-to-endæµç¨‹
pytest tests/test_integration.py -v

# 2. æ€§èƒ½åŸºå‡†æµ‹è¯•
python tests/benchmark_embedding.py

# 3. å‹åŠ›æµ‹è¯• (1000ä¸ªå¹¶å‘è¯·æ±‚)
python tests/stress_test.py --requests=1000
```

**è´¨é‡éªŒè¯**

```bash
# 1. å¯¹æ¯”embeddingè´¨é‡
python tests/compare_embeddings.py \
    --model1=sentence-transformers \
    --model2=ollama-nomic \
    --queries=è‘£äº‹é•¿æ€æƒ³åº“.txt

# 2. éªŒè¯ç›¸ä¼¼åº¦æ’å
#    ç¡®ä¿æ–°æ¨¡å‹çš„æœç´¢ç»“æœæ’åºç›¸åŒæˆ–æ›´å¥½
```

#### é˜¶æ®µ4: éƒ¨ç½² (1-2å°æ—¶)

**é‡‘ä¸é›€éƒ¨ç½² (å¯é€‰)**

```
â”œâ”€ éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ: chairman_api_test
â”œâ”€ è¿è¡Œ1å°æ—¶æ€§èƒ½ç›‘æ§
â”œâ”€ éªŒè¯æ— å¼‚å¸¸
â”œâ”€ ç°åº¦éƒ¨ç½²: 10% æµé‡ â†’ æ–°ç³»ç»Ÿ
â”œâ”€ ç›‘æ§1å°æ—¶
â”œâ”€ æ‰©å±•åˆ° 50% æµé‡
â”œâ”€ ç›‘æ§1å°æ—¶
â”œâ”€ å…¨é‡åˆ‡æ¢ (100%)
```

**ç”Ÿäº§éƒ¨ç½² (éé«˜å³°æœŸ)**

```bash
# 1. æ›´æ–°docker-compose.ymlå’Œrequirements.txt
git commit -m "feat: Ollama embedding integration"

# 2. æ„å»ºæ–°é•œåƒ
docker-compose build chairman_api

# 3. æ‰§è¡Œæ»šåŠ¨æ›´æ–° (Rolling update)
docker-compose up -d --no-deps --build chairman_api

# 4. éªŒè¯å¥åº·æ£€æŸ¥
curl http://localhost:8001/health

# 5. ç›‘æ§æ—¥å¿—
docker-compose logs -f chairman_api

# 6. éªŒè¯æœç´¢åŠŸèƒ½
curl "http://localhost:8001/api/knowledge/search?query=è‘£äº‹é•¿&top_k=5"
```

**é¢„è®¡æ—¶é—´**: 0.5-1å°æ—¶

#### é˜¶æ®µ5: ç›‘æ§å’Œä¼˜åŒ– (æŒç»­)

```
å…³é”®æŒ‡æ ‡ç›‘æ§:
â”œâ”€ Embeddingå»¶è¿Ÿ (ms)
â”‚    ç›®æ ‡: < 150ms (p99)
â”‚    è­¦å‘Š: > 200ms
â”‚
â”œâ”€ OllamaæœåŠ¡å¯ç”¨æ€§
â”‚    ç›®æ ‡: > 99.9%
â”‚
â”œâ”€ æœç´¢ç»“æœè´¨é‡
â”‚    ç›®æ ‡: ç›¸å…³åº¦è¯„åˆ† > 0.7
â”‚    æ–¹æ³•: ç”¨æˆ·åé¦ˆè¯„åˆ†
â”‚
â””â”€ ç³»ç»Ÿèµ„æºåˆ©ç”¨ç‡
     Milvuså†…å­˜: < 80%
     Ollamaå†…å­˜: < 85%
```

### 5.2 A/Bæµ‹è¯•æ–¹æ¡ˆ

#### ç›®æ ‡

éªŒè¯æ–°çš„embeddingæ¨¡å‹æ˜¯å¦æ˜¾è‘—æ”¹å–„æœç´¢è´¨é‡

#### å®ç°æ­¥éª¤

```python
# 1. é…ç½®ç®¡ç†
class EmbeddingConfig:
    MODELS = {
        "control": ("sentence-transformers", 384),
        "test_nomic": ("ollama-nomic-embed-text", 768),
        "test_mxbai": ("ollama-mxbai-embed-large", 1024),
    }

# 2. ç”¨æˆ·åˆ†ç»„
import random

def get_user_model(user_id: str) -> str:
    """æ ¹æ®ç”¨æˆ·IDè¿›è¡Œä¸€è‡´æ€§å“ˆå¸Œåˆ†ç»„"""
    hash_val = hash(user_id) % 100
    if hash_val < 50:
        return "control"
    elif hash_val < 75:
        return "test_nomic"
    else:
        return "test_mxbai"

# 3. è·¯ç”±åˆ°ä¸åŒçš„embeddingæœåŠ¡
async def retrieve_knowledge(query: str, user_id: str):
    model = get_user_model(user_id)

    if model == "control":
        results = await retriever_v1.search(query)
    elif model == "test_nomic":
        results = await retriever_v2_nomic.search(query)
    else:
        results = await retriever_v2_mxbai.search(query)

    # è®°å½•æŒ‡æ ‡
    log_metric("embedding_model", model)
    log_metric("result_count", len(results))

    return results

# 4. æ•°æ®åˆ†æ
#    æ”¶é›†ä¸¤å‘¨çš„æ•°æ®:
#    - ç‚¹å‡»ç‡ (CTR)
#    - æœç´¢æ—¶é—´
#    - ç”¨æˆ·æ»¡æ„åº¦è¯„åˆ†
#    - ç›¸å…³åº¦è¯„åˆ†
```

#### é¢„æœŸæŒ‡æ ‡å¯¹æ¯”

```
æŒ‡æ ‡                    Control (ST)   Test (Nomic)    æ”¹è¿›
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å¹³å‡ç›¸å…³åº¦åˆ†æ•°          0.72          0.81           +12.5%
ç”¨æˆ·ç‚¹å‡»ç‡              42%           48%            +14%
æœç´¢æ—¶é—´ (ms)          95            110            -15% (å¯æ¥å—)
ç”¨æˆ·æ»¡æ„åº¦è¯„åˆ†          3.8/5         4.2/5          +10%
ç³»ç»Ÿèµ„æºå ç”¨å¢åŠ         -             +50%           å¯æ§
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ç»Ÿè®¡æ˜¾è‘—æ€§: p < 0.05 (è‡³å°‘2å‘¨æ•°æ®, n > 10000)
```

### 5.3 å›æ»šæ–¹æ¡ˆ

#### åœºæ™¯1: æ–°æ¨¡å‹æ€§èƒ½ä¸è¾¾é¢„æœŸ

```bash
# 1. å¿«é€Ÿæ¢å¤åˆ°æ—§ç³»ç»Ÿ (< 5åˆ†é’Ÿ)
docker-compose down

# 2. æ¢å¤Milvusæ•°æ®å¤‡ä»½
docker volume rm chairman_milvus
# æ¢å¤å¤‡ä»½çš„Milvusæ•°æ®

# 3. å›é€€ä»£ç 
git checkout <previous_commit>
docker-compose up -d

# 4. éªŒè¯ç³»ç»Ÿ
curl http://localhost:8001/health
```

#### åœºæ™¯2: ä¿ç•™ä¸¤ä¸ªç³»ç»Ÿå¹¶åˆ‡æ¢

```bash
# 1. ä¿ç•™æ—§çš„Milvusé›†åˆ
#    æ—§æ•°æ®: chairman_thoughts (384ç»´)
#    æ–°æ•°æ®: chairman_thoughts_v2 (768ç»´)

# 2. é€šè¿‡ç‰¹æ€§å¼€å…³åˆ‡æ¢
EMBEDDING_MODEL_SWITCH = "chairman_thoughts"  # or "chairman_thoughts_v2"

# 3. æŸ¥è¯¢æ—¶é€‰æ‹©åˆé€‚çš„é›†åˆ
def retrieve_knowledge(query, use_new=False):
    model = EmbeddingModel.nomic if use_new else EmbeddingModel.minilm
    collection = "chairman_thoughts_v2" if use_new else "chairman_thoughts"

    embedding = model.encode(query)
    results = milvus.search(collection, embedding)
    return results

# 4. é€æ­¥åˆ‡æ¢
# åˆæœŸ: use_new=False (100%)
# 1å‘¨å: use_new=True (10%)
# 2å‘¨å: use_new=True (50%)
# 3å‘¨å: use_new=True (100%)
```

---

## 6. åœ¨Chairman-Agenté¡¹ç›®ä¸­çš„å…·ä½“å½±å“

### 6.1 KnowledgeRetriever æ”¹åŠ¨è¯¦æƒ…

**æ–‡ä»¶**: `/home/user/chairman-agent/src/retrieval/knowledge_retriever.py`

**ä¸»è¦æ”¹åŠ¨**:

| æ–¹æ³•/å±æ€§ | å½“å‰çŠ¶æ€ | æ–°çŠ¶æ€ | å½±å“ |
|---------|--------|--------|------|
| `__init__` | åˆå§‹åŒ–SentenceTransformer | åˆå§‹åŒ–HTTPå®¢æˆ·ç«¯ + Ollamaè¿æ¥éªŒè¯ | æ·»åŠ 5-10ç§’å¯åŠ¨æ—¶é—´éªŒè¯ |
| `_embed_text` | åŒæ­¥numpyè°ƒç”¨ | å¼‚æ­¥HTTPè°ƒç”¨ + é‡è¯•æœºåˆ¶ | æ”¹ä¸ºasyncï¼Œéœ€æ›´æ–°è°ƒç”¨æ–¹ |
| `_search_milvus` | æ¥å—384ç»´å‘é‡ | æ¥å—768ç»´å‘é‡ (æˆ–æ›´å¤§) | è‡ªåŠ¨å…¼å®¹ (æ— éœ€æ”¹åŠ¨) |
| `embedding_model` | SentenceTransformerå¯¹è±¡ | å­—ç¬¦ä¸² (æ¨¡å‹å) | ç®€åŒ–é…ç½® |
| `embedding_cache` | æ—  | æ–°å¢å¯é€‰ç¼“å­˜ | æå‡æ€§èƒ½ |
| `error_handling` | åŸºç¡€try-catch | å®Œæ•´çš„é‡è¯• + é™çº§ | æå‡å¯é æ€§ |

**ä»£ç å˜æ›´å½±å“èŒƒå›´**:

```python
# æ”¹åŠ¨å‰: 11è¡Œåˆå§‹åŒ–ä»£ç 
self.embedding_model = SentenceTransformer(config.MODEL_EMBEDDING)

# æ”¹åŠ¨å: 30-50è¡Œåˆå§‹åŒ– + éªŒè¯
self.ollama_url = f"http://{config.OLLAMA_HOST}:{config.OLLAMA_PORT}"
self.http_client = httpx.AsyncClient()
self._verify_ollama_connectivity()
self._verify_vector_dimension()

# å½±å“: KnowledgeRetrieveråˆå§‹åŒ–æ—¶é—´ +100-200ms

# æ”¹åŠ¨å‰: 6è¡Œembeddingä»£ç 
def _embed_text(self, text):
    embedding = self.embedding_model.encode(text, convert_to_tensor=False)
    return embedding.tolist()

# æ”¹åŠ¨å: 20-30è¡Œ (å«é‡è¯•)
async def _embed_text(self, text):
    for attempt in range(3):
        try:
            response = await self.http_client.post(...)
            return response.json()["embeddings"][0]
        except Exception as e:
            if attempt == 2: raise
            await asyncio.sleep(0.5 * (2 ** attempt))

# å½±å“: éœ€è¦å°†retrieve_knowledgeæ”¹ä¸ºasyncå‡½æ•°
```

**å¯èƒ½çš„å…¼å®¹æ€§é—®é¢˜**:

```python
# é—®é¢˜1: async/awaitéœ€è¦ä¼ æ’­
# æ—§ä»£ç 
result = retriever.retrieve_knowledge(query)  # åŒæ­¥

# æ–°ä»£ç 
result = await retriever.retrieve_knowledge(query)  # å¼‚æ­¥
# éœ€è¦åœ¨FastAPIè·¯ç”±å±‚å¤„ç†

# è§£å†³: åˆ›å»ºåŒæ­¥åŒ…è£…å™¨
def retrieve_knowledge_sync(query: str):
    """åŒæ­¥åŒ…è£…ï¼Œç”¨äºFastAPIè·¯ç”±"""
    return asyncio.run(
        retriever.retrieve_knowledge_async(query)
    )

# é—®é¢˜2: FastAPIè·¯ç”±éœ€è¦é€‚é…
# ä¿®æ”¹å‰
@router.get("/search")
def search(query: str):
    return retriever.retrieve_knowledge(query)

# ä¿®æ”¹å
@router.get("/search")
async def search(query: str):
    return await retriever.retrieve_knowledge(query)
```

### 6.2 DataSyncEngine æ”¹åŠ¨è¯¦æƒ…

**æ–‡ä»¶**: `/home/user/chairman-agent/src/sync_service/sync_engine.py`

**ä¸»è¦æ”¹åŠ¨**:

```python
# 1. å‘é‡ç»´åº¦é…ç½®
# ä¿®æ”¹å‰
FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=384)

# ä¿®æ”¹å
FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)

# 2. å‘é‡åŒ–è°ƒç”¨
# ä¿®æ”¹å‰
embedding = self.retriever._embed_text(note['content'])  # åŒæ­¥

# ä¿®æ”¹å
embedding = await self.retriever._embed_text(note['content'])  # å¼‚æ­¥

# 3. å‘é‡ç»´åº¦éªŒè¯ (æ–°å¢)
if len(embedding) != config.MILVUS_VECTOR_DIM:
    logger.error(f"ç»´åº¦ä¸åŒ¹é…: {len(embedding)} vs {config.MILVUS_VECTOR_DIM}")
    raise ValueError("Vector dimension mismatch")

# 4. æ‰¹å¤„ç†ä¼˜åŒ– (å¯é€‰)
async def _embed_batch(self, texts: List[str]) -> List[List[float]]:
    """æ‰¹é‡embeddingï¼Œæå‡ååé‡"""
    response = await self.http_client.post(
        f"{self.retriever.ollama_url}/api/embed",
        json={"model": self.retriever.embedding_model, "input": texts}
    )
    return response.json()["embeddings"]
```

**å½±å“åˆ†æ**:

```
æ€§èƒ½å½±å“:
â”œâ”€ å•æ¡embedding: 50-100ms â†’ 100-150ms (å¢åŠ 50-100ms)
â”œâ”€ æ‰¹å¤„ç†1000æ¡:
â”‚   æ—§: 1000 * 50ms = 50ç§’ (é¡ºåº)
â”‚   æ–°: 1000æ¡ / (1000æ¡/ç§’) = 1ç§’ (HTTPæ‰¹å¤„ç†)
â”‚   æ”¹è¿›: 50x
â”‚
â””â”€ æ•´ä½“åŒæ­¥æ—¶é—´:
    10000æ¡æ–‡æ¡£:
      æ—§: ~500ç§’ (é¡ºåºembedding)
      æ–°: ~10ç§’ (HTTPæ‰¹å¤„ç†)
      æ”¹è¿›: 50x

æ•°æ®åº“å½±å“:
â”œâ”€ å­˜å‚¨ç©ºé—´: 384ç»´ Ã— 4å­—èŠ‚ â†’ 768ç»´ Ã— 4å­—èŠ‚ = 2å€
â”œâ”€ æ’å…¥æ€§èƒ½: å½±å“ä¸å¤§ (Milvusè‡ªåŠ¨ä¼˜åŒ–)
â””â”€ æŸ¥è¯¢æ€§èƒ½: -10-15% (æ›´é«˜ç»´åº¦æœç´¢æ›´æ…¢)
```

### 6.3 Milvus é…ç½®æ”¹åŠ¨

**å½“å‰é…ç½®** (`docker-compose.yml`):

```yaml
  milvus:
    image: milvusdb/milvus:latest
    # ... å…¶ä»–é…ç½® ...
    environment:
      # éœ€è¦ç¡®ä¿å‘é‡ç»´åº¦ä¸é…ç½®ä¸€è‡´
```

**æ”¹åŠ¨æ¸…å•**:

```python
# src/config.py
MILVUS_VECTOR_DIM: int = 768  # ä»384æ”¹ä¸º768

# src/sync_service/sync_engine.py
FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)

# æ•°æ®è¿ç§»è„šæœ¬
def migrate_milvus_collections():
    """
    è¿ç§»ç­–ç•¥:
    1. åˆ›å»ºæ–°é›†åˆ (chairman_thoughts_v2)
    2. è¿ç§»æ•°æ®
    3. åˆ‡æ¢æŸ¥è¯¢åˆ°æ–°é›†åˆ
    4. åˆ é™¤æ—§é›†åˆ
    """
    pass
```

**å¯èƒ½çš„é—®é¢˜**:

```
1. é›†åˆå·²å­˜åœ¨ä¸”ç»´åº¦ä¸åŒ¹é…
   é”™è¯¯: "Collection schema mismatch"
   è§£å†³:
   a. åˆ é™¤æ—§é›†åˆ: collection.drop()
   b. åˆ›å»ºæ–°é›†åˆ (è‡ªåŠ¨å‘ç”Ÿåœ¨åˆå§‹åŒ–)

2. Milvusç£ç›˜ç©ºé—´ä¸è¶³
   å½±å“: 768ç»´ vs 384ç»´ = 2å€å­˜å‚¨
   è®¡ç®—: 10000æ¡ Ã— 768 Ã— 4å­—èŠ‚ = ~30MB
   è§£å†³: é¢„ç•™è¶³å¤Ÿç£ç›˜ç©ºé—´

3. ç´¢å¼•æ„å»ºç¼“æ…¢
   å½±å“: å‘é‡ç»´åº¦è¶Šé«˜ï¼Œç´¢å¼•æ„å»ºè¶Šæ…¢
   æ—¶é—´: 384ç»´ ~30ç§’ â†’ 768ç»´ ~60ç§’
   è§£å†³: åœ¨éé«˜å³°æœŸè¿›è¡Œ
```

### 6.4 Docker å®¹å™¨åŒ–æ”¹åŠ¨

**docker-compose.yml æ–°å¢æœåŠ¡**:

```yaml
  # æ–°å¢OllamaæœåŠ¡
  ollama:
    image: ollama/ollama:latest
    container_name: chairman_ollama
    ports:
      - "11434:11434"
    volumes:
      - ./data/ollama:/root/.ollama
    networks:
      - chairman_network
    environment:
      OLLAMA_MODELS: /root/.ollama/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
    command: serve
```

**ä¿®æ”¹chairman_apiæœåŠ¡**:

```yaml
  chairman_api:
    # ... ç°æœ‰é…ç½® ...
    depends_on:
      milvus:
        condition: service_healthy
      ollama:  # æ–°å¢ä¾èµ–
        condition: service_healthy
    environment:
      # æ–°å¢ç¯å¢ƒå˜é‡
      OLLAMA_HOST=ollama
      OLLAMA_PORT=11434
      # ä¿®æ”¹å‘é‡ç»´åº¦
      MILVUS_VECTOR_DIM=768
```

**Dockerfile ä¿®æ”¹**:

```dockerfile
# ä¿®æ”¹å‰
RUN pip install --no-cache-dir -r requirements.txt

# ä¿®æ”¹å
# åˆ é™¤sentence-transformers, å‡å°‘é•œåƒå¤§å° ~450MB
RUN pip install --no-cache-dir -r requirements.txt

# æœ€ç»ˆé•œåƒå¤§å°: ~2GB â†’ ~1.5GB (å‡å°‘)
```

**å¯åŠ¨é¡ºåº**:

```
1. surreal (SurrealDB) âœ…
2. etcd (Milvusä¾èµ–) âœ…
3. minio (Milvusä¾èµ–) âœ…
4. milvus â† ä¾èµ–etcd + minio âœ…
5. redis âœ…
6. open_notebook â† ä¾èµ–surreal âœ…
7. ollama â† æ–°å¢ï¼Œç‹¬ç«‹æœåŠ¡
8. chairman_api â† ä¾èµ–æ‰€æœ‰ä¸Šè¿°æœåŠ¡
```

**å¥åº·æ£€æŸ¥**:

```bash
# éªŒè¯æ‰€æœ‰æœåŠ¡éƒ½æ­£å¸¸
curl http://localhost:11434/api/tags           # Ollama
curl http://localhost:19530/healthz            # Milvus
curl http://localhost:6379/ping                # Redis
curl http://localhost:5055/api/config          # Open-Notebook
curl http://localhost:8001/health              # Chairman API
```

### 6.5 APIç½‘å…³å½±å“

**æ–‡ä»¶**: `/home/user/chairman-agent/src/api/gateway.py`

**éœ€è¦ä¿®æ”¹çš„åœ°æ–¹**:

```python
# 1. ä¾èµ–æ³¨å…¥ - ç¡®ä¿get_retriever_instanceèƒ½å¤„ç†async
def get_retriever_instance():
    try:
        return get_retriever()
    except Exception as e:
        # ... ç°æœ‰ä»£ç  ...

# 2. å¥åº·æ£€æŸ¥ç«¯ç‚¹ - å¢åŠ Ollamaæ£€æŸ¥
@app.get("/api/health")
async def api_health_check():
    try:
        # ç°æœ‰çš„Milvusæ£€æŸ¥
        # ...

        # æ–°å¢Ollamaæ£€æŸ¥
        ollama_status = await check_ollama_health()

        return {
            "status": "healthy",
            "services": {
                "api": "âœ… running",
                "milvus": "âœ… connected",
                "ollama": "âœ… connected" if ollama_status else "âŒ unavailable",
                "retriever": "âœ… ready"
            }
        }
    except Exception as e:
        return {"status": "degraded", "error": str(e)}

# 3. é”™è¯¯å¤„ç† - Ollamaç‰¹å®šçš„é”™è¯¯
from fastapi import HTTPException

async def search_knowledge(query: str):
    try:
        result = await retriever.retrieve_knowledge(query)
        return {"status": "success", "data": result}
    except ConnectionError:
        raise HTTPException(
            status_code=503,
            detail="Ollama embedding service unavailable"
        )
    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid query: {str(e)}"
        )
```

**æ–°å¢çš„ç«¯ç‚¹** (å¯é€‰):

```python
@router.get("/admin/embedding-status")
async def get_embedding_status():
    """è·å–embeddingæœåŠ¡çŠ¶æ€"""
    return {
        "current_model": config.MODEL_EMBEDDING,
        "vector_dimension": config.MILVUS_VECTOR_DIM,
        "ollama_host": config.OLLAMA_HOST,
        "ollama_port": config.OLLAMA_PORT,
        "operational": await check_ollama_health()
    }

@router.post("/admin/test-embedding")
async def test_embedding(text: str = "æµ‹è¯•æ–‡æœ¬"):
    """æµ‹è¯•embeddingåŠŸèƒ½"""
    try:
        embedding = await retriever._embed_text(text)
        return {
            "text": text,
            "dimension": len(embedding),
            "vector_sample": embedding[:5] + ["..."]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### 6.6 æµ‹è¯•å’ŒéªŒè¯è®¡åˆ’

**ä¿®æ”¹å—å½±å“çš„æµ‹è¯•æ–‡ä»¶**:

```
tests/
â”œâ”€ test_knowledge_retriever.py (éœ€è¦å®Œå…¨æ”¹å†™)
â”‚  â”œâ”€ æ”¹ä¸ºasyncæµ‹è¯•
â”‚  â”œâ”€ mock Ollama HTTPè°ƒç”¨
â”‚  â”œâ”€ æµ‹è¯•é‡è¯•æœºåˆ¶
â”‚  â””â”€ æµ‹è¯•ç»´åº¦éªŒè¯
â”‚
â”œâ”€ test_integration.py (éœ€è¦é€‚é…)
â”‚  â”œâ”€ å¯åŠ¨Ollamaå®¹å™¨
â”‚  â”œâ”€ æµ‹è¯•end-to-endæµç¨‹
â”‚  â””â”€ æ€§èƒ½åŸºå‡†æµ‹è¯•
â”‚
â”œâ”€ test_api_gateway.py (éœ€è¦é€‚é…)
â”‚  â”œâ”€ asyncè·¯ç”±æµ‹è¯•
â”‚  â””â”€ Ollamaæ•…éšœåœºæ™¯
â”‚
â””â”€ æ–°å¢: test_ollama_embedding.py
   â”œâ”€ Ollamaè¿æ¥æµ‹è¯•
   â”œâ”€ å¤šæ¨¡å‹æµ‹è¯•
   â””â”€ æ‰¹å¤„ç†æµ‹è¯•
```

---

## 7. æ€»ä½“å»ºè®®æ€»ç»“

### 7.1 å¯è¡Œæ€§è¯„åˆ†

```
å¯è¡Œæ€§è¯„åˆ†: ğŸŸ¢ 8/10

ç»´åº¦è¯„åˆ†:
â”œâ”€ æŠ€æœ¯å¯è¡Œæ€§: â­â­â­â­â­ (å®Œå…¨å¯è¡Œ)
â”œâ”€ æ—¶é—´æˆæœ¬: â­â­â­â­ (6-13å°æ—¶å¼€å‘)
â”œâ”€ å¼€å‘å¤æ‚åº¦: â­â­â­ (ä¸­ç­‰)
â”œâ”€ æµ‹è¯•å¤æ‚åº¦: â­â­â­â­ (éœ€è¦å®Œæ•´éªŒè¯)
â”œâ”€ å›æ»šéš¾åº¦: â­â­ (å®¹æ˜“å›æ»š)
â”œâ”€ é•¿æœŸç»´æŠ¤: â­â­â­â­ (æ›´ç®€å•çš„ç»´æŠ¤)
â””â”€ ä¸šåŠ¡ä»·å€¼: â­â­â­â­â­ (æ˜¾è‘—æå‡æœç´¢è´¨é‡)
```

### 7.2 æ¨èæ–¹æ¡ˆ

```
é€‰æ‹©: ä½¿ç”¨Ollama + nomic-embed-text

åŸå› :
1. âœ… æœ€ä½³æ€§èƒ½/è´¨é‡/æˆæœ¬å‡è¡¡
2. âœ… 768ç»´ç›¸æ¯”384ç»´ (+7-9% è´¨é‡æå‡)
3. âœ… 8Kä¸Šä¸‹æ–‡æ”¯æŒï¼ˆæœªæ¥è¯æ˜ï¼‰
4. âœ… å®Œå…¨å¼€æºï¼Œæ— è®¸å¯é—®é¢˜
5. âœ… ç¤¾åŒºæ´»è·ƒï¼Œæ–‡æ¡£å®Œå–„

è¿ç§»è·¯å¾„:
1. éƒ¨ç½²OllamaæœåŠ¡ (2å°æ—¶)
2. ä¿®æ”¹åº”ç”¨ä»£ç  (2-4å°æ—¶)
3. å…¨é‡é‡å»ºMilvusé›†åˆ (0.5-2å°æ—¶)
4. ç³»ç»Ÿæµ‹è¯•å’ŒéªŒè¯ (2-3å°æ—¶)
5. ç°åº¦éƒ¨ç½² (2-4å°æ—¶)
6. ç›‘æ§å’Œä¼˜åŒ– (æŒç»­)

æ€»è€—æ—¶: 9-15å°æ—¶ (åŒ…æ‹¬æ‰€æœ‰å‡†å¤‡å’Œæµ‹è¯•)

å®æ–½çª—å£: é€‰æ‹©éé«˜å³°æœŸï¼Œé¢„è®¡åœæœºæ—¶é—´ < 2å°æ—¶
```

### 7.3 é£é™©å’Œç¼“è§£æªæ–½

```
é£é™©åˆ†å¸ƒ:

ğŸ”´ é«˜é£é™© (ä½å¯èƒ½æ€§ï¼Œé«˜å½±å“)
â”œâ”€ OllamaæœåŠ¡æ•…éšœ
â”‚  â””â”€ ç¼“è§£: å®ç°é™çº§æ–¹æ¡ˆï¼Œæ”¯æŒå¤‡ç”¨æ¨¡å‹

ğŸŸ¡ ä¸­é£é™© (ä¸­å¯èƒ½æ€§ï¼Œä¸­å½±å“)
â”œâ”€ å‘é‡ç»´åº¦ä¸åŒ¹é…å¯¼è‡´æ•°æ®ä¸¢å¤±
â”‚  â””â”€ ç¼“è§£: ä¸¥æ ¼çš„ç»´åº¦éªŒè¯ï¼Œå®Œæ•´çš„æ•°æ®å¤‡ä»½
â”œâ”€ å¼‚æ­¥ä»£ç å¼•å…¥çš„å¹¶å‘é—®é¢˜
â”‚  â””â”€ ç¼“è§£: å®Œæ•´çš„å•å…ƒå’Œé›†æˆæµ‹è¯•

ğŸŸ¢ ä½é£é™© (é«˜å¯èƒ½æ€§ï¼Œä½å½±å“)
â”œâ”€ ç½‘ç»œå»¶è¿Ÿå¢åŠ 
â”‚  â””â”€ ç¼“è§£: è¿æ¥å¤ç”¨ï¼Œæ‰¹å¤„ç†
â”œâ”€ å†…å­˜å ç”¨å¢åŠ 
â”‚  â””â”€ ç¼“è§£: ç›‘æ§å‘Šè­¦ï¼Œè‡ªåŠ¨æ‰©å®¹
```

### 7.4 æˆåŠŸæ ‡å‡†

è¿ç§»æˆåŠŸéœ€è¦æ»¡è¶³ä»¥ä¸‹æ¡ä»¶:

```
1. åŠŸèƒ½å®Œæ•´æ€§ âœ…
   â”œâ”€ æ‰€æœ‰æœç´¢æŸ¥è¯¢è¿”å›æ­£ç¡®ç»“æœ
   â””â”€ APIå“åº”æ ¼å¼ä¿æŒä¸å˜

2. æ€§èƒ½æŒ‡æ ‡ âœ…
   â”œâ”€ P99å»¶è¿Ÿ < 150ms (ç›¸å¯¹æ¥å—)
   â”œâ”€ å¯ç”¨æ€§ > 99.5%
   â””â”€ ååé‡ â‰¥ 1000 queries/sec

3. è´¨é‡æ”¹è¿› âœ…
   â”œâ”€ æœç´¢ç›¸å…³åº¦è¯„åˆ† > 0.75
   â”œâ”€ ç”¨æˆ·æ»¡æ„åº¦è¯„åˆ† â‰¥ 4.0/5.0
   â””â”€ ç‚¹å‡»ç‡æå‡ > 10%

4. ç³»ç»Ÿå¥åº·åº¦ âœ…
   â”œâ”€ Ollamaå¯ç”¨æ€§ > 99.9%
   â”œâ”€ Milvuså“åº”æ—¶é—´ < 50ms
   â””â”€ æ— OOMäº‹ä»¶

5. è¿ç»´èƒ½åŠ› âœ…
   â”œâ”€ å®Œæ•´çš„ç›‘æ§å‘Šè­¦
   â”œâ”€ å¿«é€Ÿå›æ»šèƒ½åŠ› (< 5åˆ†é’Ÿ)
   â””â”€ æ˜ç¡®çš„æ•…éšœå¤„ç†SOP
```

---

## 8. å‚è€ƒèµ„æºå’Œæ–‡æ¡£é“¾æ¥

### 8.1 å®˜æ–¹æ–‡æ¡£

- [Ollamaå®˜ç½‘](https://ollama.ai)
- [Ollama Embeddingsæ–‡æ¡£](https://docs.ollama.com/capabilities/embeddings)
- [Ollama APIè§„èŒƒ](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [Milvuså‘é‡æ•°æ®åº“æ–‡æ¡£](https://milvus.io/docs)
- [SentenceTransformersæ–‡æ¡£](https://sbert.net)

### 8.2 æŠ€æœ¯èµ„æº

- [Nomic Embedæ–‡ç« ](https://www.nomic.ai/blog)
- [ä½¿ç”¨Ollama + Milvusæ„å»ºRAG](https://milvus.io/docs/build_RAG_with_milvus_and_ollama.md)
- [å‘é‡æ•°æ®åº“è¿ç§»ç»éªŒ](https://medium.com/vector-database-migrations)
- [MTEBæ’è¡Œæ¦œ](https://huggingface.co/spaces/mteb/leaderboard)

### 8.3 æœ¬é¡¹ç›®ç›¸å…³æ–‡ä»¶

å½“å‰éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶:
```
/home/user/chairman-agent/
â”œâ”€ src/config.py
â”œâ”€ src/retrieval/knowledge_retriever.py
â”œâ”€ src/sync_service/sync_engine.py
â”œâ”€ src/services/knowledge_service.py
â”œâ”€ src/api/gateway.py
â”œâ”€ requirements.txt
â”œâ”€ docker-compose.yml
â”œâ”€ Dockerfile
â””â”€ tests/test_knowledge_retriever.py
```

---

## 9. åç»­è¡ŒåŠ¨æ­¥éª¤

### å³æ—¶è¡ŒåŠ¨ (æœ¬å‘¨)

- [ ] å®¡æŸ¥æœ¬åˆ†ææŠ¥å‘Š
- [ ] ç¡®è®¤embeddingæ¨¡å‹é€‰æ‹© (æ¨è: nomic-embed-text)
- [ ] å‡†å¤‡å¼€å‘ç¯å¢ƒ
- [ ] åˆ›å»ºfeatureåˆ†æ”¯

### çŸ­æœŸè¡ŒåŠ¨ (1-2å‘¨)

- [ ] å®Œæˆä»£ç å¼€å‘
- [ ] é€šè¿‡æ‰€æœ‰æµ‹è¯•
- [ ] è¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] å‡†å¤‡éƒ¨ç½²è®¡åˆ’

### éƒ¨ç½²è¡ŒåŠ¨

- [ ] é€‰æ‹©éƒ¨ç½²çª—å£ (éé«˜å³°æœŸ)
- [ ] å¤‡ä»½ç°æœ‰æ•°æ®
- [ ] ç°åº¦éƒ¨ç½²
- [ ] å…¨é‡åˆ‡æ¢
- [ ] ç›‘æ§å’Œä¼˜åŒ–

---

**æŠ¥å‘Šç”Ÿæˆæ—¥æœŸ**: 2025-11-23
**åˆ†æå¸ˆ**: Chairman Agent Team
**ç‰ˆæœ¬**: 1.0
**çŠ¶æ€**: å°±ç»ªæ‰§è¡Œ

