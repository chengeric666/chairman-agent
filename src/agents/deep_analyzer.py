# src/agents/deep_analyzer.py
# MVP-3: æ·±åº¦åˆ†æAgent - æ€æƒ³ä½“ç³»åŒ–å’Œä¼šè®®åˆ†æçš„é›†æˆå®ç°

import logging
from typing import Optional, Dict, Any, List
from datetime import datetime
from src.langchain_openrouter import ChatOpenRouter

from src.config import config
from src.retrieval.knowledge_retriever import get_retriever
from src.agents.prompts import (
    THOUGHT_ANALYSIS_SYSTEM_PROMPT,
    THOUGHT_ANALYSIS_PROMPT,
    MEETING_ANALYSIS_SYSTEM_PROMPT,
    MEETING_ANALYSIS_PROMPT,
)

logger = logging.getLogger(__name__)


class DeepAnalyzerAgent:
    """æ·±åº¦åˆ†æAgent - MVP-3çš„æ ¸å¿ƒ

    åŠŸèƒ½ï¼š
    1. æ€æƒ³ä½“ç³»åŒ–åˆ†æ
    2. ä¼šè®®å†³ç­–é€»è¾‘æç‚¼
    3. ç®¡ç†åŸåˆ™è¯†åˆ«
    4. æ·±åº¦ç ”ç©¶å’Œæ´å¯Ÿ
    5. çŸ¥è¯†ä½“ç³»åŒ–æ€»ç»“
    """

    def __init__(self):
        """åˆå§‹åŒ–æ·±åº¦åˆ†æAgent"""
        self.retriever = get_retriever()

        # ä½¿ç”¨æ¨ç†æ¨¡å‹è¿›è¡Œæ·±åº¦åˆ†æ
        self.llm = ChatOpenRouter(
            openrouter_api_key=config.OPENROUTER_API_KEY,
            model=config.MODEL_REASONING,  # ä½¿ç”¨æ¨ç†æ¨¡å‹
            temperature=0.5,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç²¾ç¡®çš„åˆ†æ
            max_tokens=config.LLM_MAX_TOKENS
        )

        logger.info("âœ… DeepAnalyzerAgentåˆå§‹åŒ–å®Œæˆ")

    def systemize_thought(self, topic: str, depth_level: str = "high") -> Dict[str, Any]:
        """ä½“ç³»åŒ–æ€æƒ³ - MVP-3æ ¸å¿ƒåŠŸèƒ½

        Args:
            topic: è¦ä½“ç³»åŒ–çš„ä¸»é¢˜
            depth_level: åˆ†ææ·±åº¦ï¼ˆlow/medium/highï¼‰

        Returns:
            ä½“ç³»åŒ–ç»“æœ
        """
        logger.info(f"ğŸ§  æ€æƒ³ä½“ç³»åŒ–åˆ†æ: {topic} (æ·±åº¦:{depth_level})")

        try:
            # æ ¹æ®æ·±åº¦çº§åˆ«è°ƒæ•´top_k
            top_k_map = {"low": 5, "medium": 10, "high": 15}
            top_k = top_k_map.get(depth_level, 10)

            # ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³èµ„æ–™
            knowledge = self.retriever.retrieve_knowledge(topic, top_k=top_k)

            if not knowledge or knowledge.strip() == "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³èµ„æ–™":
                return {
                    "status": "insufficient_data",
                    "topic": topic,
                    "message": "çŸ¥è¯†åº“ä¸­æ²¡æœ‰è¶³å¤Ÿçš„ç›¸å…³èµ„æ–™è¿›è¡Œä½“ç³»åŒ–åˆ†æ"
                }

            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = THOUGHT_ANALYSIS_PROMPT.format(
                topic=topic,
                knowledge_base_context=knowledge
            )

            # è°ƒç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æ
            result = self.llm.invoke(prompt)

            logger.info(f"âœ… æ€æƒ³ä½“ç³»åŒ–å®Œæˆ: {topic}")

            return {
                "status": "success",
                "topic": topic,
                "depth_level": depth_level,
                "analysis": result.content,
                "knowledge_sources": knowledge,
                "timestamp": datetime.utcnow().isoformat(),
                "type": "thought_systemization"
            }

        except Exception as e:
            logger.error(f"âŒ æ€æƒ³ä½“ç³»åŒ–å¤±è´¥: {e}")
            return {
                "status": "failed",
                "topic": topic,
                "error": str(e)
            }

    def analyze_meeting(self,
                       meeting_name: str,
                       transcript: str,
                       meeting_date: Optional[str] = None,
                       context: Optional[str] = None) -> Dict[str, Any]:
        """æ·±åº¦åˆ†æä¼šè®®è®°å½•

        Args:
            meeting_name: ä¼šè®®åç§°
            transcript: ä¼šè®®è®°å½•/è½¬å½•
            meeting_date: ä¼šè®®æ—¥æœŸ
            context: ä¼šè®®èƒŒæ™¯ä¿¡æ¯

        Returns:
            ä¼šè®®åˆ†æç»“æœ
        """
        logger.info(f"ğŸ“‹ åˆ†æä¼šè®®: {meeting_name}")

        try:
            # ä»ä¼šè®®å†…å®¹è¯†åˆ«æ ¸å¿ƒä¸»é¢˜
            core_topic = self._extract_core_topic(transcript)

            # è·å–ç›¸å…³èƒŒæ™¯çŸ¥è¯†
            background_knowledge = self.retriever.retrieve_knowledge(
                core_topic,
                top_k=8
            )

            meeting_date = meeting_date or datetime.now().strftime("%Y-%m-%d")

            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = MEETING_ANALYSIS_PROMPT.format(
                meeting_name=meeting_name,
                meeting_date=meeting_date,
                core_topic=core_topic,
                meeting_transcript=transcript,
                knowledge_base_context=background_knowledge
            )

            # è°ƒç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æ
            result = self.llm.invoke(prompt)

            logger.info(f"âœ… ä¼šè®®åˆ†æå®Œæˆ: {meeting_name}")

            return {
                "status": "success",
                "meeting_name": meeting_name,
                "meeting_date": meeting_date,
                "core_topic": core_topic,
                "analysis": result.content,
                "background_knowledge": background_knowledge,
                "timestamp": datetime.utcnow().isoformat(),
                "type": "meeting_analysis"
            }

        except Exception as e:
            logger.error(f"âŒ ä¼šè®®åˆ†æå¤±è´¥: {e}")
            return {
                "status": "failed",
                "meeting_name": meeting_name,
                "error": str(e)
            }

    def extract_principles(self, topic: str) -> Dict[str, Any]:
        """æå–å’Œç³»ç»ŸåŒ–ç®¡ç†åŸåˆ™

        Args:
            topic: ä¸»é¢˜

        Returns:
            ç®¡ç†åŸåˆ™æå–ç»“æœ
        """
        logger.info(f"ğŸ“Œ æå–ç®¡ç†åŸåˆ™: {topic}")

        try:
            knowledge = self.retriever.retrieve_knowledge(topic, top_k=12)

            principles_prompt = f"""
è¯·æ·±å…¥åˆ†æè‘£äº‹é•¿å…³äº"{topic}"çš„æ€æƒ³ä¸­åŒ…å«çš„æ ¸å¿ƒç®¡ç†åŸåˆ™ã€‚

ã€ç›¸å…³èµ„æ–™ã€‘ï¼š
{knowledge}

ã€åˆ†æä»»åŠ¡ã€‘
1. **æœ€æ ¸å¿ƒçš„åŸåˆ™**ï¼šè¿™ä¸ªä¸»é¢˜æœ€æ ¸å¿ƒçš„ç®¡ç†åŸåˆ™æ˜¯ä»€ä¹ˆï¼Ÿ
2. **åŸåˆ™çš„å†…æ¶µ**ï¼šè¿™ä¸ªåŸåˆ™çš„æ·±å±‚å«ä¹‰å’Œæœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿ
3. **å¤šç»´åº¦åº”ç”¨**ï¼šè¿™ä¸ªåŸåˆ™åœ¨æˆ˜ç•¥ã€äººæ‰ã€åˆ›æ–°ã€æ‰§è¡Œç­‰ç»´åº¦å¦‚ä½•åº”ç”¨ï¼Ÿ
4. **åŸåˆ™ä¹‹é—´çš„å…³ç³»**ï¼šå¤šä¸ªåŸåˆ™ä¹‹é—´çš„é€»è¾‘å…³ç³»å¦‚ä½•ï¼Ÿ
5. **å“²å­¦åŸºç¡€**ï¼šè¿™äº›åŸåˆ™åŸºäºä»€ä¹ˆæ ·çš„ä»·å€¼è§‚å’Œä¸–ç•Œè§‚ï¼Ÿ
6. **å®è·µéªŒè¯**ï¼šè¿™äº›åŸåˆ™åœ¨å®è·µä¸­æ˜¯å¦‚ä½•éªŒè¯çš„ï¼Ÿ
7. **ä¼ æ‰¿æ„ä¹‰**ï¼šå¯¹äºç®¡ç†å±‚å­¦ä¹ å’Œä¼ æ‰¿çš„æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ

ã€è¾“å‡ºæ ¼å¼ã€‘
## æ ¸å¿ƒåŸåˆ™ä½“ç³»
[ä½“ç³»åŒ–å‘ˆç°æ‰€æœ‰è¯†åˆ«çš„åŸåˆ™]

## åŸåˆ™çš„æ·±å±‚å«ä¹‰
[é€ä¸ªåˆ†ææ¯ä¸ªåŸåˆ™çš„æœ¬è´¨å’Œå†…æ¶µ]

## åº”ç”¨ç»´åº¦åˆ†æ
[åœ¨ä¸åŒç»´åº¦çš„å…·ä½“åº”ç”¨]

## åŸåˆ™çš„å“²å­¦åŸºç¡€
[åˆ†æä»·å€¼è§‚å’Œä¸–ç•Œè§‚åŸºç¡€]

## ç®¡ç†å®è·µå¯ç¤º
[å¯¹ç®¡ç†å±‚çš„å…·ä½“å¯ç¤º]
"""

            result = self.llm.invoke(principles_prompt)

            return {
                "status": "success",
                "topic": topic,
                "principles": result.content,
                "timestamp": datetime.utcnow().isoformat()
            }

        except Exception as e:
            logger.error(f"âŒ åŸåˆ™æå–å¤±è´¥: {e}")
            return {
                "status": "failed",
                "error": str(e)
            }

    def identify_connections(self, topics: List[str]) -> Dict[str, Any]:
        """è¯†åˆ«å¤šä¸ªæ€æƒ³ä¹‹é—´çš„å…³è”å’Œå…³ç³»

        Args:
            topics: ä¸»é¢˜åˆ—è¡¨

        Returns:
            å…³è”åˆ†æç»“æœ
        """
        logger.info(f"ğŸ”— è¯†åˆ«æ€æƒ³å…³è”: {topics}")

        try:
            # è·å–æ‰€æœ‰ä¸»é¢˜çš„èµ„æ–™
            knowledge_map = {}
            for topic in topics:
                knowledge_map[topic] = self.retriever.retrieve_knowledge(topic, top_k=5)

            # æ„å»ºå…³è”åˆ†ææç¤ºè¯
            topics_str = "ã€".join(topics)
            knowledge_str = "\n\n".join([
                f"ã€{topic}çš„æ€æƒ³ã€‘ï¼š\n{knowledge_map[topic]}"
                for topic in topics
            ])

            connection_prompt = f"""
è¯·æ·±åº¦åˆ†æè‘£äº‹é•¿å…³äºä»¥ä¸‹ä¸»é¢˜çš„æ€æƒ³ä¹‹é—´çš„å…³è”å’Œç›¸äº’å…³ç³»ã€‚

ã€ä¸»é¢˜ã€‘ï¼š{topics_str}

ã€ç›¸å…³èµ„æ–™ã€‘ï¼š
{knowledge_str}

ã€åˆ†æç»´åº¦ã€‘
1. **å…±åŒåŸºç¡€**ï¼šè¿™äº›æ€æƒ³åŸºäºä»€ä¹ˆæ ·çš„å…±åŒåŸåˆ™æˆ–ä»·å€¼è§‚ï¼Ÿ
2. **å†…åœ¨é€»è¾‘**ï¼šå®ƒä»¬ä¹‹é—´å¦‚ä½•ç›¸äº’æ”¯æŒå’Œè¡¥å……ï¼Ÿ
3. **æ¼”è¿›å…³ç³»**ï¼šè¿™äº›æ€æƒ³æ˜¯å¦‚ä½•ç›¸äº’æ¼”è¿›å’Œæ·±åŒ–çš„ï¼Ÿ
4. **åº”ç”¨ååŒ**ï¼šåœ¨å®è·µä¸­å¦‚ä½•ååŒå‘æŒ¥ä½œç”¨ï¼Ÿ
5. **ä½“ç³»æ€§**ï¼šè¿™äº›æ€æƒ³å½¢æˆçš„å®Œæ•´ä½“ç³»æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ
6. **ä¼˜å…ˆçº§**ï¼šåœ¨è‘£äº‹é•¿çš„æ€æƒ³ä½“ç³»ä¸­çš„é‡è¦æ€§é¡ºåºå¦‚ä½•ï¼Ÿ

ã€è¾“å‡ºæ ¼å¼ã€‘
## æ€æƒ³ä½“ç³»æ¦‚è§ˆ
[æ€»ä½“å‘ˆç°è¿™äº›æ€æƒ³å¦‚ä½•å½¢æˆæœ‰æœºçš„æ•´ä½“]

## é€å¯¹å…³è”åˆ†æ
[åˆ†æä»»æ„ä¸¤ä¸ªä¸»é¢˜ä¹‹é—´çš„å…³è”]

## å®Œæ•´ä½“ç³»æ¡†æ¶
[å‘ˆç°æ‰€æœ‰ä¸»é¢˜å½¢æˆçš„æ€æƒ³æ¡†æ¶]

## ååŒåº”ç”¨æŒ‡å—
[å¦‚ä½•åœ¨å®è·µä¸­ååŒåº”ç”¨è¿™äº›æ€æƒ³]
"""

            result = self.llm.invoke(connection_prompt)

            return {
                "status": "success",
                "topics": topics,
                "connections": result.content,
                "timestamp": datetime.utcnow().isoformat()
            }

        except Exception as e:
            logger.error(f"âŒ å…³è”åˆ†æå¤±è´¥: {e}")
            return {
                "status": "failed",
                "error": str(e)
            }

    def comprehensive_research(self, topic: str, research_questions: Optional[List[str]] = None) -> Dict[str, Any]:
        """è¿›è¡Œç»¼åˆæ€§çš„æ·±åº¦ç ”ç©¶

        Args:
            topic: ç ”ç©¶ä¸»é¢˜
            research_questions: ç ”ç©¶é—®é¢˜åˆ—è¡¨

        Returns:
            ç ”ç©¶ç»“æœ
        """
        logger.info(f"ğŸ”¬ è¿›è¡Œç»¼åˆæ€§æ·±åº¦ç ”ç©¶: {topic}")

        try:
            # è·å–ç›¸å…³çŸ¥è¯†
            knowledge = self.retriever.retrieve_knowledge(topic, top_k=20)

            # é»˜è®¤ç ”ç©¶é—®é¢˜
            if not research_questions:
                research_questions = [
                    "è‘£äº‹é•¿å…³äºè¿™ä¸ªä¸»é¢˜çš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "è¿™ä¸ªæ€æƒ³çš„æ¼”è¿›è¿‡ç¨‹å¦‚ä½•ï¼Ÿ",
                    "åœ¨å®è·µä¸­æœ‰å“ªäº›æˆåŠŸçš„åº”ç”¨æ¡ˆä¾‹ï¼Ÿ",
                    "å­˜åœ¨çš„ä¸»è¦æŒ‘æˆ˜å’Œåº”å¯¹æ–¹å¼æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "å¯¹æœªæ¥å‘å±•çš„å¯ç¤ºæ˜¯ä»€ä¹ˆï¼Ÿ"
                ]

            # æ„å»ºç ”ç©¶æç¤ºè¯
            questions_str = "\n".join([f"{i+1}. {q}" for i, q in enumerate(research_questions)])

            research_prompt = f"""
è¯·å¯¹ä»¥ä¸‹ä¸»é¢˜è¿›è¡Œç»¼åˆæ€§çš„æ·±åº¦ç ”ç©¶ï¼Œç³»ç»Ÿå›ç­”æå‡ºçš„ç ”ç©¶é—®é¢˜ã€‚

ã€ç ”ç©¶ä¸»é¢˜ã€‘ï¼š{topic}

ã€ç ”ç©¶é—®é¢˜ã€‘ï¼š
{questions_str}

ã€å‚è€ƒèµ„æ–™ã€‘ï¼š
{knowledge}

ã€ç ”ç©¶è¦æ±‚ã€‘
1. ç³»ç»Ÿæ€§ï¼šæŒ‰ç…§é€»è¾‘é¡ºåºç»„ç»‡ç­”æ¡ˆ
2. æ·±åº¦æ€§ï¼šå……åˆ†æŒ–æ˜é—®é¢˜çš„æœ¬è´¨
3. å®Œæ•´æ€§ï¼šå…¨é¢è¦†ç›–æ‰€æœ‰ç ”ç©¶é—®é¢˜
4. è¯æ®æ€§ï¼šå…³é”®è®ºç‚¹è¦æœ‰åŸæ–‡å¼•ç”¨æ”¯æ’‘
5. å¯å‘æ€§ï¼šæä¾›æœ‰ä»·å€¼çš„æ–°æ´å¯Ÿ

ã€è¾“å‡ºæ ¼å¼ã€‘
## ç ”ç©¶ç»¼è¿°
[å¯¹ä¸»é¢˜çš„å…¨é¢è®¤è¯†]

## é€é—®è§£ç­”
### é—®é¢˜1: [é—®é¢˜]
[æ·±åº¦å›ç­”å’Œåˆ†æ]

### é—®é¢˜2: [é—®é¢˜]
[æ·±åº¦å›ç­”å’Œåˆ†æ]

...

## ç»¼åˆå¯ç¤º
[å¯¹ç®¡ç†å®è·µçš„ç»¼åˆå¯ç¤º]

## å»¶ä¼¸æ€è€ƒ
[å¯ä»¥è¿›ä¸€æ­¥ç ”ç©¶çš„ç›¸å…³é—®é¢˜]
"""

            result = self.llm.invoke(research_prompt)

            return {
                "status": "success",
                "topic": topic,
                "research_questions": research_questions,
                "research_result": result.content,
                "timestamp": datetime.utcnow().isoformat()
            }

        except Exception as e:
            logger.error(f"âŒ æ·±åº¦ç ”ç©¶å¤±è´¥: {e}")
            return {
                "status": "failed",
                "error": str(e)
            }

    def _extract_core_topic(self, transcript: str) -> str:
        """ä»ä¼šè®®è®°å½•ä¸­æå–æ ¸å¿ƒä¸»é¢˜

        Args:
            transcript: ä¼šè®®è®°å½•

        Returns:
            æ ¸å¿ƒä¸»é¢˜
        """
        sentences = transcript.split("ã€‚")
        if len(sentences) > 0:
            # è¿”å›ç¬¬ä¸€å¥çš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºä¸»é¢˜
            core = sentences[0].strip()
            return core[:100] if len(core) > 100 else core

        return "ä¼šè®®ä¸»é¢˜"


# å…¨å±€å®ä¾‹
_deep_analyzer_instance: Optional[DeepAnalyzerAgent] = None


def get_deep_analyzer() -> DeepAnalyzerAgent:
    """è·å–æ·±åº¦åˆ†æAgentå®ä¾‹"""
    global _deep_analyzer_instance

    if _deep_analyzer_instance is None:
        _deep_analyzer_instance = DeepAnalyzerAgent()

    return _deep_analyzer_instance
