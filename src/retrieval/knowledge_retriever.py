# src/retrieval/knowledge_retriever.py
# å†…éƒ¨çŸ¥è¯†åº“æŸ¥è¯¢å·¥å…· - ä¸ºAgentæä¾›"æŸ¥è¯¢è‘£äº‹é•¿æ€æƒ³"çš„èƒ½åŠ›

from typing import List, Dict, Optional
import logging
from datetime import datetime
import numpy as np
from langchain_core.tools import tool
from pymilvus import Collection, connections

from src.config import config
from src.retrieval.ollama_embedding_client import get_ollama_client

logger = logging.getLogger(__name__)


class KnowledgeRetriever:
    """
    çŸ¥è¯†åº“æŸ¥è¯¢å™¨

    åŠŸèƒ½ï¼š
    1. å°†æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ–
    2. åœ¨Milvusä¸­æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢
    3. è¿”å›æœ€ç›¸å…³çš„è‘£äº‹é•¿æ€æƒ³èµ„æ–™
    4. æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤ï¼ˆæ—¥æœŸã€æ ‡ç­¾ç­‰ï¼‰
    """

    def __init__(self):
        """åˆå§‹åŒ–çŸ¥è¯†åº“æŸ¥è¯¢å™¨"""
        self.milvus_host = config.MILVUS_HOST
        self.milvus_port = config.MILVUS_PORT
        self.db_name = config.MILVUS_DB_NAME
        self.collection_name = config.MILVUS_COLLECTION_NAME

        # Ollama embeddingå®¢æˆ·ç«¯ï¼ˆHTTPè°ƒç”¨ï¼Œé¿å…æœ¬åœ°æ¨¡å‹åŠ è½½ï¼‰
        self.embedding_client = get_ollama_client()

        # è¿æ¥Milvus
        self._connect_milvus()

        logger.info("âœ… çŸ¥è¯†åº“æŸ¥è¯¢å™¨åˆå§‹åŒ–å®Œæˆ")

    def _connect_milvus(self):
        """è¿æ¥åˆ°Milvus"""
        try:
            connections.connect(
                alias="default",
                host=self.milvus_host,
                port=self.milvus_port
            )
            logger.info(f"âœ… å·²è¿æ¥Milvus ({self.milvus_host}:{self.milvus_port})")
        except Exception as e:
            logger.error(f"âŒ è¿æ¥Milvuså¤±è´¥: {e}")
            raise

    def retrieve_knowledge(
        self,
        query: str,
        top_k: int = None,
        similarity_threshold: float = None,
        filters: Optional[Dict] = None
    ) -> str:
        """
        ä»è‘£äº‹é•¿çš„çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹

        Args:
            query: æŸ¥è¯¢çš„ä¸»é¢˜æˆ–é—®é¢˜
            top_k: è¿”å›æœ€ç›¸å…³çš„Kæ¡ç»“æœï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®å€¼ï¼‰
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®å€¼ï¼‰
            filters: å¯é€‰çš„è¿‡æ»¤æ¡ä»¶ (ä¾‹å¦‚: {"date_range": ["2024-01-01", "2024-12-31"]})

        Returns:
            æ ¼å¼åŒ–çš„æ£€ç´¢ç»“æœå­—ç¬¦ä¸²
        """
        top_k = top_k or config.RETRIEVAL_TOP_K
        similarity_threshold = similarity_threshold or config.RETRIEVAL_SIMILARITY_THRESHOLD

        logger.info(f"ğŸ“š æŸ¥è¯¢çŸ¥è¯†åº“: {query}")

        try:
            # 1. å°†æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ–
            query_embedding = self._embed_text(query)

            # 2. åœ¨Milvusä¸­æ‰§è¡Œå‘é‡æœç´¢
            search_results = self._search_milvus(
                embedding=query_embedding,
                top_k=top_k,
                similarity_threshold=similarity_threshold
            )

            if not search_results:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ç›¸å…³èµ„æ–™")
                return "æœªæ‰¾åˆ°ç›¸å…³èµ„æ–™ã€‚è¯·å°è¯•å…¶ä»–æŸ¥è¯¢è¯ã€‚"

            # 3. æ ¼å¼åŒ–ç»“æœ
            formatted = self._format_results(search_results)

            logger.info(f"âœ… æ‰¾åˆ° {len(search_results)} æ¡ç›¸å…³èµ„æ–™")
            return formatted

        except Exception as e:
            logger.error(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
            raise

    def _embed_text(self, text: str) -> List[float]:
        """
        ä½¿ç”¨Ollamaè¿œç¨‹æœåŠ¡å‘é‡åŒ–æ–‡æœ¬

        Args:
            text: è¦å‘é‡åŒ–çš„æ–‡æœ¬

        Returns:
            å‘é‡ï¼ˆæµ®ç‚¹æ•°åˆ—è¡¨ï¼‰
        """
        try:
            # ä½¿ç”¨åŒæ­¥åŒ…è£…å™¨è°ƒç”¨Ollama embedding API
            embedding = self.embedding_client.embed_single_sync(text)

            if embedding is None:
                raise ValueError("Ollama embeddingè¿”å›Noneï¼ŒæœåŠ¡å¯èƒ½ä¸å¯ç”¨")

            return embedding
        except Exception as e:
            logger.error(f"âŒ å‘é‡åŒ–å¤±è´¥: {e}")
            raise

    def _search_milvus(
        self,
        embedding: List[float],
        top_k: int = 10,
        similarity_threshold: float = 0.5
    ) -> List[Dict]:
        """
        åœ¨Milvusä¸­æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢

        Args:
            embedding: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›æœ€ç›¸å…³çš„Kæ¡ç»“æœ
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            collection = Collection(self.collection_name)
            collection.load()

            # æ‰§è¡Œæœç´¢
            results = collection.search(
                data=[embedding],
                anns_field="embedding",
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=top_k,
                output_fields=["note_id", "content", "metadata", "created_at"]
            )

            # å¤„ç†ç»“æœ
            processed_results = []
            for hits in results:
                for hit in hits:
                    # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆæ³¨æ„L2è·ç¦»éœ€è¦è½¬æ¢ï¼‰
                    distance = hit.distance
                    similarity_score = 1 / (1 + distance)  # ç®€å•çš„è·ç¦»-ç›¸ä¼¼åº¦è½¬æ¢

                    if similarity_score >= similarity_threshold:
                        processed_results.append({
                            "note_id": hit.entity.get("note_id"),
                            "content": hit.entity.get("content"),
                            "similarity_score": similarity_score,
                            "metadata": hit.entity.get("metadata", {}),
                            "created_at": hit.entity.get("created_at")
                        })

            return processed_results

        except Exception as e:
            logger.error(f"âŒ Milvusæœç´¢å¤±è´¥: {e}")
            raise

    def _format_results(self, results: List[Dict]) -> str:
        """
        å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸ºå¯è¯»çš„æ–‡æœ¬

        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„æ–‡æœ¬
        """
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³èµ„æ–™ã€‚"

        formatted = "## ğŸ“š ç›¸å…³çš„è‘£äº‹é•¿æ€æƒ³èµ„æ–™ï¼š\n\n"

        for i, result in enumerate(results, 1):
            formatted += f"### èµ„æ–™ {i}\n"
            formatted += f"**ç›¸å…³åº¦**ï¼š{result['similarity_score']:.1%}\n"

            if result.get('created_at'):
                formatted += f"**æ—¥æœŸ**ï¼š{result['created_at']}\n"

            if result.get('metadata'):
                metadata = result['metadata']
                if metadata.get('tags'):
                    formatted += f"**æ ‡ç­¾**ï¼š{', '.join(metadata['tags'])}\n"

            formatted += f"\n{result['content']}\n\n"
            formatted += "---\n\n"

        return formatted

    # LangChain Toolè£…é¥°å™¨ - ç”¨äºAgenté›†æˆ
    @tool
    def query_tool(self, query: str, top_k: int = 5) -> str:
        """
        LangChain Tool: æŸ¥è¯¢å†…éƒ¨çŸ¥è¯†åº“

        è¿™ä¸ªå·¥å…·å¯ä»¥è¢«OpenDeepResearch Agentç›´æ¥ä½¿ç”¨

        Args:
            query: æŸ¥è¯¢çš„ä¸»é¢˜
            top_k: è¿”å›çš„ç»“æœæ•°é‡

        Returns:
            æ ¼å¼åŒ–çš„çŸ¥è¯†åº“æœç´¢ç»“æœ
        """
        return self.retrieve_knowledge(query, top_k=top_k)


# å…¨å±€å®ä¾‹
_retriever_instance: Optional[KnowledgeRetriever] = None


def get_retriever() -> KnowledgeRetriever:
    """è·å–æˆ–åˆ›å»ºçŸ¥è¯†åº“æ£€ç´¢å™¨å®ä¾‹"""
    global _retriever_instance
    if _retriever_instance is None:
        _retriever_instance = KnowledgeRetriever()
    return _retriever_instance
