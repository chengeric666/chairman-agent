# Ollama Embeddingè¿ç§» - å®ç°æŒ‡å—

æœ¬æ–‡æ¡£æä¾›ä»SentenceTransformersè¿ç§»åˆ°Ollama Embeddingçš„å…·ä½“æ­¥éª¤å’Œä»£ç ç¤ºä¾‹ã€‚

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

```bash
# 1. å®‰è£…Ollama
curl https://ollama.ai/install.sh | sh

# 2. å¯åŠ¨OllamaæœåŠ¡
ollama serve

# 3. æ‹‰å–embeddingæ¨¡å‹ (åœ¨å¦ä¸€ä¸ªç»ˆç«¯)
ollama pull nomic-embed-text
# æˆ–å…¶ä»–æ¨¡å‹
# ollama pull mxbai-embed-large
# ollama pull all-minilm:l6-v2
```

### éªŒè¯Ollamaå®‰è£…

```bash
# æµ‹è¯•API
curl http://localhost:11434/api/tags

# æµ‹è¯•embedding
curl http://localhost:11434/api/embed -d '{
  "model": "nomic-embed-text",
  "input": ["test"]
}' | jq .

# è¾“å‡ºåº”è¯¥æ˜¾ç¤º768ç»´å‘é‡
```

---

## ä»£ç å®ç°

### æ­¥éª¤1: ä¿®æ”¹é…ç½®æ–‡ä»¶

**æ–‡ä»¶**: `src/config.py`

```python
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    # ==================== Ollama é…ç½® ====================
    OLLAMA_HOST: str = os.getenv("OLLAMA_HOST", "localhost")
    OLLAMA_PORT: int = int(os.getenv("OLLAMA_PORT", "11434"))

    # ==================== åµŒå…¥æ¨¡å‹é…ç½® ====================
    # é€‰é¡¹: "nomic-embed-text" (æ¨è), "all-minilm:l6-v2", "mxbai-embed-large"
    MODEL_EMBEDDING: str = os.getenv("MODEL_EMBEDDING", "nomic-embed-text")

    # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹æ›´æ–°å‘é‡ç»´åº¦
    EMBEDDING_MODEL_DIMS = {
        "nomic-embed-text": 768,
        "all-minilm:l6-v2": 384,
        "mxbai-embed-large": 1024,
    }

    MILVUS_VECTOR_DIM: int = EMBEDDING_MODEL_DIMS.get(MODEL_EMBEDDING, 768)

    # Ollamaè¶…æ—¶é…ç½® (ç§’)
    OLLAMA_TIMEOUT: int = int(os.getenv("OLLAMA_TIMEOUT", "60"))

    # è¿æ¥æ± é…ç½®
    OLLAMA_MAX_RETRIES: int = 3
    OLLAMA_RETRY_DELAY: float = 0.5  # ç§’

    # ==================== å…¶ä»–é…ç½®ä¿æŒä¸å˜ ====================
    MILVUS_HOST: str = os.getenv("MILVUS_HOST", "localhost")
    MILVUS_PORT: int = int(os.getenv("MILVUS_PORT", "19530"))
    # ... å…¶ä»–é…ç½® ...

config = Config()
```

**ç¯å¢ƒå˜é‡** (`.env`):

```bash
# Ollama é…ç½®
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
MODEL_EMBEDDING=nomic-embed-text

# Milvus é…ç½®
MILVUS_HOST=localhost
MILVUS_PORT=19530
```

### æ­¥éª¤2: å®ç°Ollama EmbeddingæœåŠ¡

**æ–‡ä»¶**: `src/retrieval/ollama_embedding_client.py` (æ–°å»º)

```python
"""
Ollama Embeddingå®¢æˆ·ç«¯ - å¤„ç†ä¸OllamaæœåŠ¡çš„é€šä¿¡
"""

import asyncio
import logging
from typing import List, Optional
import httpx
from src.config import config

logger = logging.getLogger(__name__)


class OllamaEmbeddingClient:
    """Ollama Embedding APIå®¢æˆ·ç«¯"""

    def __init__(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        self.base_url = f"http://{config.OLLAMA_HOST}:{config.OLLAMA_PORT}"
        self.model = config.MODEL_EMBEDDING
        self.timeout = config.OLLAMA_TIMEOUT
        self.max_retries = config.OLLAMA_MAX_RETRIES
        self.retry_delay = config.OLLAMA_RETRY_DELAY

        # éªŒè¯è¿æ¥å’Œå‘é‡ç»´åº¦
        self._verify_connectivity()
        self._verify_vector_dimension()

    def _verify_connectivity(self) -> bool:
        """éªŒè¯OllamaæœåŠ¡å¯ç”¨æ€§"""
        try:
            response = httpx.get(
                f"{self.base_url}/api/tags",
                timeout=5
            )
            response.raise_for_status()

            # æ£€æŸ¥ç›®æ ‡æ¨¡å‹æ˜¯å¦å­˜åœ¨
            models = response.json().get("models", [])
            model_names = [m.get("name", "").split(":")[0] for m in models]

            if self.model not in model_names:
                logger.warning(
                    f"âš ï¸ æ¨¡å‹ {self.model} æœªæ‰¾åˆ°ï¼Œå¯ç”¨æ¨¡å‹: {model_names}"
                )
                # ç»§ç»­è¿è¡Œï¼Œç­‰å¾…æ¨¡å‹åŠ è½½

            logger.info(f"âœ… OllamaæœåŠ¡å¯ç”¨ ({self.base_url})")
            return True
        except Exception as e:
            logger.error(f"âŒ Ollamaè¿æ¥å¤±è´¥: {e}")
            raise RuntimeError(f"æ— æ³•è¿æ¥OllamaæœåŠ¡: {e}")

    def _verify_vector_dimension(self) -> None:
        """éªŒè¯å‘é‡ç»´åº¦é…ç½®æ­£ç¡®"""
        try:
            test_embedding = self._embed_sync("test")
            actual_dim = len(test_embedding)
            expected_dim = config.MILVUS_VECTOR_DIM

            if actual_dim != expected_dim:
                raise ValueError(
                    f"å‘é‡ç»´åº¦ä¸åŒ¹é…ï¼\n"
                    f"  æœŸæœ›: {expected_dim} (config.MILVUS_VECTOR_DIM)\n"
                    f"  å®é™…: {actual_dim} (æ¥è‡ª {self.model})\n"
                    f"  å»ºè®®: æ›´æ–°é…ç½®ä¸­çš„ EMBEDDING_MODEL_DIMS"
                )

            logger.info(f"âœ… å‘é‡ç»´åº¦éªŒè¯é€šè¿‡: {actual_dim}ç»´")
        except Exception as e:
            logger.error(f"âŒ å‘é‡ç»´åº¦éªŒè¯å¤±è´¥: {e}")
            raise

    def _embed_sync(self, text: str) -> List[float]:
        """åŒæ­¥embedding (ç”¨äºåˆå§‹åŒ–éªŒè¯)"""
        response = httpx.post(
            f"{self.base_url}/api/embed",
            json={"model": self.model, "input": [text]},
            timeout=self.timeout
        )
        response.raise_for_status()
        return response.json()["embeddings"][0]

    async def embed_single(self, text: str) -> List[float]:
        """å•æ¡æ–‡æœ¬embedding (å¸¦é‡è¯•)"""
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            for attempt in range(self.max_retries):
                try:
                    response = await client.post(
                        f"{self.base_url}/api/embed",
                        json={
                            "model": self.model,
                            "input": [text]
                        }
                    )
                    response.raise_for_status()
                    embeddings = response.json()["embeddings"]
                    return embeddings[0]

                except Exception as e:
                    if attempt == self.max_retries - 1:
                        logger.error(f"âŒ Embeddingå¤±è´¥ (æœ€åä¸€æ¬¡): {e}")
                        raise

                    wait_time = self.retry_delay * (2 ** attempt)
                    logger.warning(
                        f"âš ï¸ Embeddingå¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}), "
                        f"ç­‰å¾…{wait_time:.1f}såé‡è¯•: {e}"
                    )
                    await asyncio.sleep(wait_time)

    async def embed_batch(
        self,
        texts: List[str],
        batch_size: int = 32
    ) -> List[List[float]]:
        """æ‰¹é‡embedding"""
        if not texts:
            return []

        all_embeddings = []

        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]

            try:
                async with httpx.AsyncClient(timeout=self.timeout) as client:
                    response = await client.post(
                        f"{self.base_url}/api/embed",
                        json={
                            "model": self.model,
                            "input": batch
                        }
                    )
                    response.raise_for_status()
                    embeddings = response.json()["embeddings"]
                    all_embeddings.extend(embeddings)

                logger.debug(f"âœ… æ‰¹å¤„ç†å®Œæˆ: {i}/{len(texts)}")

            except Exception as e:
                logger.error(f"âŒ æ‰¹å¤„ç†å¤±è´¥: {e}")
                raise

        return all_embeddings

    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            async with httpx.AsyncClient(timeout=5) as client:
                response = await client.get(f"{self.base_url}/api/tags")
                return response.status_code == 200
        except Exception:
            return False


# å…¨å±€å®ä¾‹
_ollama_client: Optional[OllamaEmbeddingClient] = None


def get_ollama_client() -> OllamaEmbeddingClient:
    """è·å–Ollamaå®¢æˆ·ç«¯å®ä¾‹"""
    global _ollama_client
    if _ollama_client is None:
        _ollama_client = OllamaEmbeddingClient()
    return _ollama_client
```

### æ­¥éª¤3: ä¿®æ”¹KnowledgeRetriever

**æ–‡ä»¶**: `src/retrieval/knowledge_retriever.py`

```python
"""
çŸ¥è¯†åº“æŸ¥è¯¢å™¨ - ä½¿ç”¨Ollama Embedding
"""

import logging
from typing import List, Dict, Optional
from datetime import datetime
from langchain_core.tools import tool
from pymilvus import Collection, connections

from src.config import config
from src.retrieval.ollama_embedding_client import get_ollama_client

logger = logging.getLogger(__name__)


class KnowledgeRetriever:
    """çŸ¥è¯†åº“æŸ¥è¯¢å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–çŸ¥è¯†åº“æŸ¥è¯¢å™¨"""
        self.milvus_host = config.MILVUS_HOST
        self.milvus_port = config.MILVUS_PORT
        self.db_name = config.MILVUS_DB_NAME
        self.collection_name = config.MILVUS_COLLECTION_NAME

        # ä½¿ç”¨Ollamaå®¢æˆ·ç«¯æ›¿ä»£SentenceTransformer
        self.embedding_client = get_ollama_client()

        # è¿æ¥Milvus
        self._connect_milvus()

        logger.info("âœ… çŸ¥è¯†åº“æŸ¥è¯¢å™¨åˆå§‹åŒ–å®Œæˆ")

    def _connect_milvus(self):
        """è¿æ¥åˆ°Milvus"""
        try:
            connections.connect(
                alias="default",
                host=self.milvus_host,
                port=self.milvus_port
            )
            logger.info(f"âœ… å·²è¿æ¥Milvus ({self.milvus_host}:{self.milvus_port})")
        except Exception as e:
            logger.error(f"âŒ è¿æ¥Milvuså¤±è´¥: {e}")
            raise

    async def retrieve_knowledge(
        self,
        query: str,
        top_k: int = None,
        similarity_threshold: float = None,
        filters: Optional[Dict] = None
    ) -> str:
        """ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹"""
        top_k = top_k or config.RETRIEVAL_TOP_K
        similarity_threshold = similarity_threshold or config.RETRIEVAL_SIMILARITY_THRESHOLD

        logger.info(f"ğŸ“š æŸ¥è¯¢çŸ¥è¯†åº“: {query}")

        try:
            # 1. å°†æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ– (ç°åœ¨æ˜¯å¼‚æ­¥çš„)
            query_embedding = await self._embed_text(query)

            # 2. åœ¨Milvusä¸­æ‰§è¡Œå‘é‡æœç´¢
            search_results = self._search_milvus(
                embedding=query_embedding,
                top_k=top_k,
                similarity_threshold=similarity_threshold
            )

            if not search_results:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ç›¸å…³èµ„æ–™")
                return "æœªæ‰¾åˆ°ç›¸å…³èµ„æ–™ã€‚è¯·å°è¯•å…¶ä»–æŸ¥è¯¢è¯ã€‚"

            # 3. æ ¼å¼åŒ–ç»“æœ
            formatted = self._format_results(search_results)

            logger.info(f"âœ… æ‰¾åˆ° {len(search_results)} æ¡ç›¸å…³èµ„æ–™")
            return formatted

        except Exception as e:
            logger.error(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
            raise

    async def _embed_text(self, text: str) -> List[float]:
        """ä½¿ç”¨Ollamaå‘é‡åŒ–æ–‡æœ¬"""
        embedding = await self.embedding_client.embed_single(text)

        # éªŒè¯å‘é‡ç»´åº¦
        if len(embedding) != config.MILVUS_VECTOR_DIM:
            raise ValueError(
                f"å‘é‡ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{config.MILVUS_VECTOR_DIM}, "
                f"å¾—åˆ°{len(embedding)}"
            )

        return embedding

    def _search_milvus(
        self,
        embedding: List[float],
        top_k: int = 10,
        similarity_threshold: float = 0.5
    ) -> List[Dict]:
        """åœ¨Milvusä¸­æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢"""
        try:
            collection = Collection(self.collection_name)
            collection.load()

            # æ‰§è¡Œæœç´¢
            results = collection.search(
                data=[embedding],
                anns_field="embedding",
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=top_k,
                output_fields=["note_id", "content", "metadata", "created_at"]
            )

            # å¤„ç†ç»“æœ
            processed_results = []
            for hits in results:
                for hit in hits:
                    # L2è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                    distance = hit.distance
                    similarity_score = 1 / (1 + distance)

                    if similarity_score >= similarity_threshold:
                        processed_results.append({
                            "note_id": hit.entity.get("note_id"),
                            "content": hit.entity.get("content"),
                            "similarity_score": similarity_score,
                            "metadata": hit.entity.get("metadata", {}),
                            "created_at": hit.entity.get("created_at")
                        })

            return processed_results

        except Exception as e:
            logger.error(f"âŒ Milvusæœç´¢å¤±è´¥: {e}")
            raise

    def _format_results(self, results: List[Dict]) -> str:
        """å°†æœç´¢ç»“æœæ ¼å¼åŒ–"""
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³èµ„æ–™ã€‚"

        formatted = "## ğŸ“š ç›¸å…³çš„è‘£äº‹é•¿æ€æƒ³èµ„æ–™ï¼š\n\n"

        for i, result in enumerate(results, 1):
            formatted += f"### èµ„æ–™ {i}\n"
            formatted += f"**ç›¸å…³åº¦**ï¼š{result['similarity_score']:.1%}\n"

            if result.get('created_at'):
                formatted += f"**æ—¥æœŸ**ï¼š{result['created_at']}\n"

            if result.get('metadata'):
                metadata = result['metadata']
                if metadata.get('tags'):
                    formatted += f"**æ ‡ç­¾**ï¼š{', '.join(metadata['tags'])}\n"

            formatted += f"\n{result['content']}\n\n"
            formatted += "---\n\n"

        return formatted

    @tool
    def query_tool(self, query: str, top_k: int = 5) -> str:
        """LangChain Tool: æŸ¥è¯¢å†…éƒ¨çŸ¥è¯†åº“"""
        import asyncio
        return asyncio.run(self.retrieve_knowledge(query, top_k=top_k))


# å…¨å±€å®ä¾‹
_retriever_instance: Optional[KnowledgeRetriever] = None


def get_retriever() -> KnowledgeRetriever:
    """è·å–æˆ–åˆ›å»ºçŸ¥è¯†åº“æ£€ç´¢å™¨å®ä¾‹"""
    global _retriever_instance
    if _retriever_instance is None:
        _retriever_instance = KnowledgeRetriever()
    return _retriever_instance
```

### æ­¥éª¤4: ä¿®æ”¹DataSyncEngine

**æ–‡ä»¶**: `src/sync_service/sync_engine.py`

å…³é”®æ”¹åŠ¨:

```python
# 1. å¯¼å…¥
from src.retrieval.ollama_embedding_client import get_ollama_client

# 2. ä¿®æ”¹åˆå§‹åŒ–
def __init__(self, retriever: KnowledgeRetriever):
    """..."""
    self.embedding_client = get_ollama_client()

# 3. ä¿®æ”¹Milvus schema
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="note_id", dtype=DataType.VARCHAR, max_length=256),
    FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=65535),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR,
                dim=config.MILVUS_VECTOR_DIM),  # ä½¿ç”¨é…ç½®çš„ç»´åº¦
    FieldSchema(name="metadata", dtype=DataType.VARCHAR, max_length=65535),
    FieldSchema(name="created_at", dtype=DataType.VARCHAR, max_length=100),
    FieldSchema(name="updated_at", dtype=DataType.VARCHAR, max_length=100),
]

# 4. ä¿®æ”¹embeddingè°ƒç”¨
async def sync_once(self, full_sync: bool = False):
    # ...

    # ä½¿ç”¨æ‰¹é‡embeddingæå‡æ€§èƒ½
    texts = [note['content'] for note in notes]
    embeddings = await self.embedding_client.embed_batch(texts, batch_size=32)

    for note, embedding in zip(notes, embeddings):
        # éªŒè¯å‘é‡ç»´åº¦
        if len(embedding) != config.MILVUS_VECTOR_DIM:
            logger.error(f"ç»´åº¦ä¸åŒ¹é…: {len(embedding)} != {config.MILVUS_VECTOR_DIM}")
            raise ValueError("Vector dimension mismatch")

        processed_items.append({
            "note_id": note.get('id'),
            "content": note.get('content'),
            "embedding": embedding,
            "metadata": note.get('metadata', {}),
            "created_at": note.get('created_at'),
            "updated_at": datetime.utcnow().isoformat(),
        })
```

### æ­¥éª¤5: ä¿®æ”¹APIç½‘å…³

**æ–‡ä»¶**: `src/api/gateway.py`

```python
import asyncio

# ä¿®æ”¹è·¯ç”±ä¸ºasync
@app.get("/api/knowledge/search")
async def search_knowledge(
    query: str = Query(..., description="æœç´¢æŸ¥è¯¢"),
    top_k: int = Query(10, description="è¿”å›ç»“æœæ•°", ge=1, le=50),
):
    """æœç´¢çŸ¥è¯†åº“"""
    try:
        logger.info(f"ğŸ“š æœç´¢çŸ¥è¯†åº“: {query}")
        retriever = get_retriever()
        result = await retriever.retrieve_knowledge(query, top_k=top_k)
        return {
            "status": "success",
            "data": result
        }
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")

# å¢å¼ºçš„å¥åº·æ£€æŸ¥
@app.get("/api/health")
async def api_health_check():
    """è¯¦ç»†çš„å¥åº·æ£€æŸ¥"""
    try:
        from src.retrieval.ollama_embedding_client import get_ollama_client

        ollama_client = get_ollama_client()
        ollama_health = await ollama_client.health_check()

        return {
            "status": "healthy",
            "services": {
                "api": "âœ… running",
                "milvus": "âœ… connected",
                "ollama": "âœ… connected" if ollama_health else "âš ï¸ degraded",
                "retriever": "âœ… ready"
            },
            "embedding": {
                "model": config.MODEL_EMBEDDING,
                "vector_dimension": config.MILVUS_VECTOR_DIM
            },
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "status": "degraded",
            "error": str(e)
        }
```

### æ­¥éª¤6: ä¿®æ”¹requirements.txt

```txt
# åˆ é™¤
# sentence-transformers==2.2.2

# ä¿ç•™ç°æœ‰çš„ä¾èµ–
httpx==0.25.2
pymilvus==2.3.4
# ... å…¶ä»–ä¾èµ– ...
```

### æ­¥éª¤7: ä¿®æ”¹docker-compose.yml

```yaml
version: '3.8'

services:
  # ... ç°æœ‰æœåŠ¡ ...

  # æ–°å¢: OllamaæœåŠ¡
  ollama:
    image: ollama/ollama:latest
    container_name: chairman_ollama
    ports:
      - "11434:11434"
    volumes:
      - ./data/ollama:/root/.ollama
    networks:
      - chairman_network
    environment:
      OLLAMA_MODELS: /root/.ollama/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    command: serve

  # ä¿®æ”¹: chairman_apiæœåŠ¡
  chairman_api:
    # ... ç°æœ‰é…ç½® ...
    depends_on:
      milvus:
        condition: service_healthy
      redis:
        condition: service_healthy
      open_notebook:
        condition: service_healthy
      ollama:  # æ–°å¢ä¾èµ–
        condition: service_healthy
    environment:
      # ç°æœ‰ç¯å¢ƒå˜é‡
      # ...
      # æ–°å¢Ollamaé…ç½®
      OLLAMA_HOST=ollama
      OLLAMA_PORT=11434
      MODEL_EMBEDDING=nomic-embed-text
      # ä¿®æ”¹å‘é‡ç»´åº¦
      MILVUS_VECTOR_DIM=768
```

---

## æ•°æ®è¿ç§»

### åˆ›å»ºè¿ç§»è„šæœ¬

**æ–‡ä»¶**: `scripts/migrate_embeddings.py` (æ–°å»º)

```python
"""
å‘é‡æ•°æ®è¿ç§»è„šæœ¬ - ä»384ç»´è¿ç§»åˆ°768ç»´
"""

import asyncio
import logging
from typing import List
from pymilvus import Collection, connections
from src.config import config
from src.retrieval.ollama_embedding_client import get_ollama_client

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def migrate_embeddings(
    old_collection_name: str = "chairman_thoughts",
    new_collection_name: str = "chairman_thoughts_v2"
):
    """
    è¿ç§»å‘é‡æ•°æ®åˆ°æ–°ç»´åº¦

    æ­¥éª¤:
    1. ä»æ—§é›†åˆè¯»å–æ•°æ®
    2. ä½¿ç”¨æ–°embeddingæ¨¡å‹é‡æ–°å‘é‡åŒ–
    3. å†™å…¥æ–°é›†åˆ
    4. éªŒè¯æ•°æ®å®Œæ•´æ€§
    """

    # è¿æ¥Milvus
    connections.connect(
        alias="default",
        host=config.MILVUS_HOST,
        port=config.MILVUS_PORT
    )

    # è·å–embeddingå®¢æˆ·ç«¯
    embedding_client = get_ollama_client()

    # è¯»å–æ—§é›†åˆçš„æ•°æ®
    old_collection = Collection(old_collection_name)
    old_collection.load()

    # æŸ¥è¯¢æ‰€æœ‰æ•°æ®
    logger.info(f"è¯»å–é›†åˆ {old_collection_name}...")
    results = old_collection.query(
        expr="id >= 0",
        output_fields=["note_id", "content", "metadata", "created_at"]
    )

    logger.info(f"æ‰¾åˆ° {len(results)} æ¡è®°å½•")

    # æ‰¹é‡é‡æ–°å‘é‡åŒ–
    logger.info("é‡æ–°ç”Ÿæˆå‘é‡...")
    texts = [r["content"] for r in results]
    new_embeddings = await embedding_client.embed_batch(
        texts,
        batch_size=32
    )

    # åˆ›å»ºæ–°é›†åˆ
    logger.info(f"åˆ›å»ºæ–°é›†åˆ {new_collection_name}...")
    from pymilvus import FieldSchema, CollectionSchema, DataType

    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="note_id", dtype=DataType.VARCHAR, max_length=256),
        FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=65535),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768),
        FieldSchema(name="metadata", dtype=DataType.VARCHAR, max_length=65535),
        FieldSchema(name="created_at", dtype=DataType.VARCHAR, max_length=100),
        FieldSchema(name="updated_at", dtype=DataType.VARCHAR, max_length=100),
    ]

    schema = CollectionSchema(fields, description="Chairman Agent Knowledge Base V2")
    new_collection = Collection(name=new_collection_name, schema=schema)
    new_collection.create_index(
        field_name="embedding",
        index_params={"metric_type": "L2"}
    )

    # æ’å…¥æ–°æ•°æ®
    logger.info(f"æ’å…¥æ•°æ®åˆ° {new_collection_name}...")
    data_to_insert = {
        "note_id": [r["note_id"] for r in results],
        "content": [r["content"] for r in results],
        "embedding": new_embeddings,
        "metadata": [str(r.get("metadata", {})) for r in results],
        "created_at": [r.get("created_at", "") for r in results],
        "updated_at": [str(datetime.utcnow().isoformat()) for r in results],
    }

    new_collection.insert(data_to_insert)
    new_collection.flush()

    # éªŒè¯æ•°æ®
    logger.info("éªŒè¯æ•°æ®å®Œæ•´æ€§...")
    old_count = old_collection.num_entities
    new_count = new_collection.num_entities

    if old_count == new_count:
        logger.info(f"âœ… è¿ç§»æˆåŠŸ! {new_count} æ¡è®°å½•")
        return True
    else:
        logger.error(f"âŒ æ•°æ®ä¸åŒ¹é…: æ—§{old_count} vs æ–°{new_count}")
        return False


if __name__ == "__main__":
    success = asyncio.run(migrate_embeddings())
    exit(0 if success else 1)
```

**è¿è¡Œè¿ç§»**:

```bash
# 1. åœæ­¢åº”ç”¨
docker-compose stop chairman_api

# 2. è¿è¡Œè¿ç§»è„šæœ¬
python scripts/migrate_embeddings.py

# 3. éªŒè¯æ–°é›†åˆ
docker-compose exec milvus python -c "
from pymilvus import Collection
c = Collection('chairman_thoughts_v2')
c.load()
print(f'æ€»æ•°: {c.num_entities}')
"

# 4. æ›´æ–°åº”ç”¨é…ç½®ä½¿ç”¨æ–°é›†åˆ
# ä¿®æ”¹ src/config.py:
# MILVUS_COLLECTION_NAME = "chairman_thoughts_v2"

# 5. é‡å¯åº”ç”¨
docker-compose up -d
```

---

## æµ‹è¯•å’ŒéªŒè¯

### å•å…ƒæµ‹è¯•

**æ–‡ä»¶**: `tests/test_ollama_embedding.py` (æ–°å»º)

```python
import pytest
import asyncio
from unittest.mock import Mock, patch, AsyncMock
from src.retrieval.ollama_embedding_client import OllamaEmbeddingClient
from src.config import config


@pytest.fixture
def embedding_client():
    """åˆ›å»ºembeddingå®¢æˆ·ç«¯"""
    with patch('src.retrieval.ollama_embedding_client.httpx'):
        client = OllamaEmbeddingClient()
        return client


@pytest.mark.asyncio
async def test_embed_single(embedding_client):
    """æµ‹è¯•å•æ¡embedding"""
    with patch.object(embedding_client, '_embed_sync') as mock:
        mock.return_value = [0.1] * config.MILVUS_VECTOR_DIM

        result = await embedding_client.embed_single("test")

        assert len(result) == config.MILVUS_VECTOR_DIM
        assert all(isinstance(x, float) for x in result)


@pytest.mark.asyncio
async def test_embed_batch(embedding_client):
    """æµ‹è¯•æ‰¹é‡embedding"""
    texts = ["text1", "text2", "text3"]

    with patch('src.retrieval.ollama_embedding_client.httpx') as mock_http:
        mock_response = AsyncMock()
        mock_response.json.return_value = {
            "embeddings": [[0.1] * config.MILVUS_VECTOR_DIM] * 3
        }
        mock_client = AsyncMock()
        mock_client.post.return_value = mock_response

        with patch.object(embedding_client, '_embed_batch') as batch_mock:
            batch_mock.return_value = [[0.1] * config.MILVUS_VECTOR_DIM] * 3

            results = await embedding_client.embed_batch(texts)

            assert len(results) == 3
            assert all(len(r) == config.MILVUS_VECTOR_DIM for r in results)


def test_vector_dimension_validation(embedding_client):
    """æµ‹è¯•å‘é‡ç»´åº¦éªŒè¯"""
    with pytest.raises(ValueError) as exc_info:
        # æ¨¡æ‹Ÿç»´åº¦ä¸åŒ¹é…
        embedding_client.MILVUS_VECTOR_DIM = 384
        embedding_client._verify_vector_dimension()

    assert "ç»´åº¦ä¸åŒ¹é…" in str(exc_info.value)
```

### é›†æˆæµ‹è¯•

**è¿è¡Œé›†æˆæµ‹è¯•**:

```bash
# ç¡®ä¿æ‰€æœ‰æœåŠ¡è¿è¡Œ
docker-compose up -d

# ç­‰å¾…æœåŠ¡å¯åŠ¨
sleep 30

# è¿è¡Œæµ‹è¯•
pytest tests/test_integration.py -v

# éªŒè¯embeddingè´¨é‡
python tests/benchmark_embeddings.py
```

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### é—®é¢˜1: Ollamaè¿æ¥å¤±è´¥

```
é”™è¯¯: "æ— æ³•è¿æ¥OllamaæœåŠ¡"

è§£å†³:
1. æ£€æŸ¥Ollamaæ˜¯å¦è¿è¡Œ: curl http://localhost:11434/api/tags
2. æ£€æŸ¥é˜²ç«å¢™/ç½‘ç»œé…ç½®
3. æ£€æŸ¥OLLAMA_HOSTé…ç½®æ­£ç¡®
```

#### é—®é¢˜2: å‘é‡ç»´åº¦ä¸åŒ¹é…

```
é”™è¯¯: "å‘é‡ç»´åº¦ä¸åŒ¹é…: æœŸæœ›768, å¾—åˆ°384"

è§£å†³:
1. ç¡®è®¤MODEL_EMBEDDINGé…ç½®æ­£ç¡®
2. æ£€æŸ¥EMBEDDING_MODEL_DIMSä¸­æ˜¯å¦æœ‰è¯¥æ¨¡å‹
3. é‡æ–°å¯åŠ¨Ollamaæ‹‰å–æ­£ç¡®çš„æ¨¡å‹: ollama pull nomic-embed-text
```

#### é—®é¢˜3: å†…å­˜ä¸è¶³

```
ç—‡çŠ¶: Ollamaè¿›ç¨‹è¢«æ€æ­»

è§£å†³:
1. å¢åŠ ç³»ç»Ÿå†…å­˜
2. ä½¿ç”¨æ›´å°çš„æ¨¡å‹: all-minilm:l6-v2 (46MB)
3. é…ç½®Ollamaé™åˆ¶: OLLAMA_MAX_LOADED_MODELS=1
```

---

## æ€§èƒ½ä¼˜åŒ–

### æ‰¹å¤„ç†é…ç½®

```python
# æ ¹æ®ç¡¬ä»¶è°ƒæ•´æ‰¹å¤§å°
BATCH_SIZES = {
    "cpu_only": 8,
    "gpu_2gb": 16,
    "gpu_6gb": 32,
    "gpu_12gb": 64,
    "gpu_24gb": 128
}
```

### ç¼“å­˜ç­–ç•¥

```python
# å®ç°embeddingç¼“å­˜
from functools import lru_cache

@lru_cache(maxsize=10000)
async def cached_embed(text: str):
    return await embedding_client.embed_single(text)
```

---

**æ›´æ–°æ—¥æœŸ**: 2025-11-23
**çŠ¶æ€**: å‡†å¤‡å°±ç»ª
